{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNppwwf2NxUKcR/dSZqF6i9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReshamWadhwa/ML-models/blob/main/src/models/logistic_regression/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46iBY6dPOzv"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX1_zEpoQBKs",
        "outputId": "6585e087-9fd4-4f7e-a3ed-72251236e6c6"
      },
      "source": [
        "data = pd.read_csv(\"suv_data.csv\")\n",
        "data.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KcewxFVHQEnP",
        "outputId": "cea31dd9-b372-4af9-ae9e-b60564b0d6d4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>Female</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510    Male   19            19000          0\n",
              "1  15810944    Male   35            20000          0\n",
              "2  15668575  Female   26            43000          0\n",
              "3  15603246  Female   27            57000          0\n",
              "4  15804002    Male   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZOypBXXRBLA"
      },
      "source": [
        "\n",
        "data = pd.concat([data, pd.get_dummies(data['Gender'], drop_first=True, prefix=\"gender\")], 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qSDRovIcRjac",
        "outputId": "319420c9-83ab-4ff4-97fe-28e319328bba"
      },
      "source": [
        "data.drop('User ID', axis = 1, inplace = True)\n",
        "data.describe()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "      <th>gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>37.655000</td>\n",
              "      <td>69742.500000</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.482877</td>\n",
              "      <td>34096.960282</td>\n",
              "      <td>0.479864</td>\n",
              "      <td>0.500526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>29.750000</td>\n",
              "      <td>43000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>70000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>46.000000</td>\n",
              "      <td>88000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>150000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age  EstimatedSalary   Purchased  gender_Male\n",
              "count  400.000000       400.000000  400.000000   400.000000\n",
              "mean    37.655000     69742.500000    0.357500     0.490000\n",
              "std     10.482877     34096.960282    0.479864     0.500526\n",
              "min     18.000000     15000.000000    0.000000     0.000000\n",
              "25%     29.750000     43000.000000    0.000000     0.000000\n",
              "50%     37.000000     70000.000000    0.000000     0.000000\n",
              "75%     46.000000     88000.000000    1.000000     1.000000\n",
              "max     60.000000    150000.000000    1.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN7ABcTrQFPl"
      },
      "source": [
        "# X = data[['Age','EstimatedSalary','gender_Male']]\n",
        "X = data.iloc[:,[1,2]].values\n",
        "Y = data['Purchased']\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size = 0.25, random_state = 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRfy4CLPQyzB",
        "outputId": "5e078c25-c39a-4972-e3fa-664d59697db7"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    20,  49000],\n",
              "       [    46,  88000],\n",
              "       [    31,  34000],\n",
              "       [    47,  30000],\n",
              "       [    35,  50000],\n",
              "       [    39,  96000],\n",
              "       [    33, 113000],\n",
              "       [    49,  86000],\n",
              "       [    45,  79000],\n",
              "       [    44,  39000],\n",
              "       [    41,  59000],\n",
              "       [    42,  53000],\n",
              "       [    35,  73000],\n",
              "       [    41,  72000],\n",
              "       [    27,  96000],\n",
              "       [    30, 116000],\n",
              "       [    41,  52000],\n",
              "       [    41,  52000],\n",
              "       [    20,  82000],\n",
              "       [    46,  41000],\n",
              "       [    27,  31000],\n",
              "       [    35,  71000],\n",
              "       [    49,  28000],\n",
              "       [    35,  91000],\n",
              "       [    37,  75000],\n",
              "       [    32, 117000],\n",
              "       [    36,  75000],\n",
              "       [    20,  86000],\n",
              "       [    38,  50000],\n",
              "       [    49,  36000],\n",
              "       [    40,  65000],\n",
              "       [    37,  77000],\n",
              "       [    60,  46000],\n",
              "       [    48, 138000],\n",
              "       [    40,  71000],\n",
              "       [    36,  63000],\n",
              "       [    26,  81000],\n",
              "       [    33,  31000],\n",
              "       [    41,  51000],\n",
              "       [    46,  74000],\n",
              "       [    18,  82000],\n",
              "       [    37,  33000],\n",
              "       [    35,  53000],\n",
              "       [    28,  59000],\n",
              "       [    37,  71000],\n",
              "       [    18,  44000],\n",
              "       [    38,  61000],\n",
              "       [    35,  65000],\n",
              "       [    31,  66000],\n",
              "       [    47,  25000],\n",
              "       [    42, 104000],\n",
              "       [    19,  19000],\n",
              "       [    21,  72000],\n",
              "       [    28,  32000],\n",
              "       [    52, 150000],\n",
              "       [    53, 104000],\n",
              "       [    25,  80000],\n",
              "       [    26,  72000],\n",
              "       [    26,  15000],\n",
              "       [    40, 142000],\n",
              "       [    35,  38000],\n",
              "       [    57, 122000],\n",
              "       [    41,  87000],\n",
              "       [    24,  89000],\n",
              "       [    37,  52000],\n",
              "       [    35, 108000],\n",
              "       [    32, 100000],\n",
              "       [    35, 147000],\n",
              "       [    19,  26000],\n",
              "       [    46,  82000],\n",
              "       [    47, 105000],\n",
              "       [    45,  45000],\n",
              "       [    38,  51000],\n",
              "       [    37,  93000],\n",
              "       [    29,  43000],\n",
              "       [    41,  30000],\n",
              "       [    40,  60000],\n",
              "       [    27,  88000],\n",
              "       [    27,  90000],\n",
              "       [    39,  71000],\n",
              "       [    23,  28000],\n",
              "       [    51, 146000],\n",
              "       [    23,  63000],\n",
              "       [    37,  80000],\n",
              "       [    40,  47000],\n",
              "       [    48,  29000],\n",
              "       [    35,  59000],\n",
              "       [    26,  30000],\n",
              "       [    39, 106000],\n",
              "       [    28,  84000],\n",
              "       [    59,  76000],\n",
              "       [    40,  57000],\n",
              "       [    35,  97000],\n",
              "       [    26,  86000],\n",
              "       [    41,  63000],\n",
              "       [    29,  47000],\n",
              "       [    26,  17000],\n",
              "       [    58,  23000],\n",
              "       [    30,  62000],\n",
              "       [    25,  33000],\n",
              "       [    59,  29000],\n",
              "       [    28,  37000],\n",
              "       [    39,  77000],\n",
              "       [    47, 107000],\n",
              "       [    52, 138000],\n",
              "       [    29,  43000],\n",
              "       [    27, 137000],\n",
              "       [    24,  55000],\n",
              "       [    40,  72000],\n",
              "       [    21,  16000],\n",
              "       [    57,  26000],\n",
              "       [    30, 135000],\n",
              "       [    48, 119000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    28,  44000],\n",
              "       [    37,  74000],\n",
              "       [    35,  27000],\n",
              "       [    37,  79000],\n",
              "       [    32, 120000],\n",
              "       [    29,  75000],\n",
              "       [    30,  17000],\n",
              "       [    25,  79000],\n",
              "       [    40, 107000],\n",
              "       [    24,  19000],\n",
              "       [    41,  72000],\n",
              "       [    38,  61000],\n",
              "       [    36, 144000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    48,  30000],\n",
              "       [    23,  20000],\n",
              "       [    55, 130000],\n",
              "       [    29, 148000],\n",
              "       [    42,  65000],\n",
              "       [    27,  54000],\n",
              "       [    37,  55000],\n",
              "       [    25,  22000],\n",
              "       [    59, 143000],\n",
              "       [    42,  54000],\n",
              "       [    27,  17000],\n",
              "       [    47,  49000],\n",
              "       [    28,  59000],\n",
              "       [    33,  69000],\n",
              "       [    31,  68000],\n",
              "       [    35,  23000],\n",
              "       [    35,  22000],\n",
              "       [    57,  33000],\n",
              "       [    30, 107000],\n",
              "       [    46,  23000],\n",
              "       [    41,  60000],\n",
              "       [    33,  41000],\n",
              "       [    33,  60000],\n",
              "       [    47,  47000],\n",
              "       [    28,  55000],\n",
              "       [    45,  32000],\n",
              "       [    35,  75000],\n",
              "       [    59,  42000],\n",
              "       [    47,  50000],\n",
              "       [    47,  51000],\n",
              "       [    35,  79000],\n",
              "       [    39,  42000],\n",
              "       [    40,  78000],\n",
              "       [    23,  48000],\n",
              "       [    39,  75000],\n",
              "       [    35,  57000],\n",
              "       [    55,  39000],\n",
              "       [    31,  71000],\n",
              "       [    28, 123000],\n",
              "       [    42,  80000],\n",
              "       [    40,  59000],\n",
              "       [    48,  74000],\n",
              "       [    21,  88000],\n",
              "       [    53,  72000],\n",
              "       [    27,  58000],\n",
              "       [    35,  47000],\n",
              "       [    28,  89000],\n",
              "       [    26,  80000],\n",
              "       [    32, 117000],\n",
              "       [    42,  75000],\n",
              "       [    33, 149000],\n",
              "       [    41,  80000],\n",
              "       [    31,  58000],\n",
              "       [    39, 134000],\n",
              "       [    27,  20000],\n",
              "       [    29,  83000],\n",
              "       [    19,  70000],\n",
              "       [    19,  85000],\n",
              "       [    29,  61000],\n",
              "       [    39, 134000],\n",
              "       [    31,  76000],\n",
              "       [    41,  72000],\n",
              "       [    26,  80000],\n",
              "       [    40,  61000],\n",
              "       [    35,  25000],\n",
              "       [    48,  96000],\n",
              "       [    42, 149000],\n",
              "       [    28,  79000],\n",
              "       [    51, 134000],\n",
              "       [    33,  28000],\n",
              "       [    42,  54000],\n",
              "       [    45,  22000],\n",
              "       [    37,  57000],\n",
              "       [    34, 112000],\n",
              "       [    35,  39000],\n",
              "       [    22,  27000],\n",
              "       [    35,  72000],\n",
              "       [    39,  59000],\n",
              "       [    20,  74000],\n",
              "       [    46,  32000],\n",
              "       [    26,  43000],\n",
              "       [    29,  83000],\n",
              "       [    55, 125000],\n",
              "       [    37, 146000],\n",
              "       [    45, 131000],\n",
              "       [    33,  43000],\n",
              "       [    41,  45000],\n",
              "       [    42,  79000],\n",
              "       [    37, 137000],\n",
              "       [    24,  84000],\n",
              "       [    32,  18000],\n",
              "       [    56, 104000],\n",
              "       [    49,  39000],\n",
              "       [    28,  85000],\n",
              "       [    53, 143000],\n",
              "       [    30,  89000],\n",
              "       [    57,  60000],\n",
              "       [    40,  75000],\n",
              "       [    41,  79000],\n",
              "       [    20,  82000],\n",
              "       [    22,  55000],\n",
              "       [    35,  88000],\n",
              "       [    54,  70000],\n",
              "       [    31,  15000],\n",
              "       [    50,  36000],\n",
              "       [    42,  65000],\n",
              "       [    34,  43000],\n",
              "       [    42, 108000],\n",
              "       [    54,  26000],\n",
              "       [    19,  21000],\n",
              "       [    36,  50000],\n",
              "       [    37,  70000],\n",
              "       [    36, 126000],\n",
              "       [    47,  20000],\n",
              "       [    30,  79000],\n",
              "       [    59,  83000],\n",
              "       [    29,  80000],\n",
              "       [    43, 112000],\n",
              "       [    38,  80000],\n",
              "       [    58, 144000],\n",
              "       [    36, 125000],\n",
              "       [    49,  28000],\n",
              "       [    18,  52000],\n",
              "       [    30,  15000],\n",
              "       [    59,  88000],\n",
              "       [    27,  57000],\n",
              "       [    38,  71000],\n",
              "       [    31,  89000],\n",
              "       [    47,  34000],\n",
              "       [    31,  74000],\n",
              "       [    37,  72000],\n",
              "       [    40,  57000],\n",
              "       [    59, 130000],\n",
              "       [    49,  65000],\n",
              "       [    48,  90000],\n",
              "       [    46,  22000],\n",
              "       [    54, 104000],\n",
              "       [    35,  20000],\n",
              "       [    49, 141000],\n",
              "       [    48,  41000],\n",
              "       [    35,  55000],\n",
              "       [    36,  60000],\n",
              "       [    32, 150000],\n",
              "       [    18,  68000],\n",
              "       [    24,  55000],\n",
              "       [    42,  90000],\n",
              "       [    38,  59000],\n",
              "       [    60, 108000],\n",
              "       [    22,  63000],\n",
              "       [    24,  32000],\n",
              "       [    46,  59000],\n",
              "       [    48, 134000],\n",
              "       [    41,  72000],\n",
              "       [    50,  44000],\n",
              "       [    38,  71000],\n",
              "       [    24,  23000],\n",
              "       [    35,  61000],\n",
              "       [    37,  80000],\n",
              "       [    24,  27000],\n",
              "       [    26,  84000],\n",
              "       [    34,  25000],\n",
              "       [    36,  54000],\n",
              "       [    21,  68000],\n",
              "       [    41,  71000],\n",
              "       [    60,  42000],\n",
              "       [    52,  90000],\n",
              "       [    20,  23000],\n",
              "       [    51,  23000],\n",
              "       [    46,  79000],\n",
              "       [    30,  49000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "927rMMzdQzed",
        "outputId": "e06e1074-dca7-4365-a634-4ef7a9b9838a"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    36,  33000],\n",
              "       [    39,  61000],\n",
              "       [    36, 118000],\n",
              "       [    39, 122000],\n",
              "       [    26, 118000],\n",
              "       [    38,  65000],\n",
              "       [    20,  36000],\n",
              "       [    49,  89000],\n",
              "       [    31,  18000],\n",
              "       [    48, 141000],\n",
              "       [    34,  72000],\n",
              "       [    39,  73000],\n",
              "       [    35,  72000],\n",
              "       [    48, 131000],\n",
              "       [    53,  82000],\n",
              "       [    56, 133000],\n",
              "       [    60,  83000],\n",
              "       [    27,  58000],\n",
              "       [    28,  87000],\n",
              "       [    60, 102000],\n",
              "       [    40,  75000],\n",
              "       [    50,  88000],\n",
              "       [    44, 139000],\n",
              "       [    47,  43000],\n",
              "       [    45,  26000],\n",
              "       [    26,  15000],\n",
              "       [    58,  47000],\n",
              "       [    49,  74000],\n",
              "       [    53,  34000],\n",
              "       [    52, 114000],\n",
              "       [    39,  42000],\n",
              "       [    19,  76000],\n",
              "       [    18,  86000],\n",
              "       [    57,  74000],\n",
              "       [    27,  84000],\n",
              "       [    30,  80000],\n",
              "       [    22,  18000],\n",
              "       [    32,  86000],\n",
              "       [    50,  20000],\n",
              "       [    19,  25000],\n",
              "       [    47, 144000],\n",
              "       [    58, 101000],\n",
              "       [    34, 115000],\n",
              "       [    23,  66000],\n",
              "       [    56,  60000],\n",
              "       [    31, 118000],\n",
              "       [    48,  35000],\n",
              "       [    47, 113000],\n",
              "       [    39,  79000],\n",
              "       [    52,  38000],\n",
              "       [    24,  58000],\n",
              "       [    37,  53000],\n",
              "       [    42,  80000],\n",
              "       [    46,  28000],\n",
              "       [    42,  73000],\n",
              "       [    37,  62000],\n",
              "       [    60,  42000],\n",
              "       [    36,  52000],\n",
              "       [    58,  95000],\n",
              "       [    43, 129000],\n",
              "       [    27,  89000],\n",
              "       [    23,  82000],\n",
              "       [    38, 112000],\n",
              "       [    35,  50000],\n",
              "       [    36,  99000],\n",
              "       [    37, 144000],\n",
              "       [    26,  35000],\n",
              "       [    42,  70000],\n",
              "       [    43, 133000],\n",
              "       [    38,  50000],\n",
              "       [    46,  96000],\n",
              "       [    35,  44000],\n",
              "       [    38, 113000],\n",
              "       [    39,  71000],\n",
              "       [    26,  52000],\n",
              "       [    54, 108000],\n",
              "       [    33,  51000],\n",
              "       [    26,  16000],\n",
              "       [    30,  87000],\n",
              "       [    35,  60000],\n",
              "       [    29,  28000],\n",
              "       [    45,  22000],\n",
              "       [    46, 117000],\n",
              "       [    32,  18000],\n",
              "       [    22,  81000],\n",
              "       [    25,  87000],\n",
              "       [    48,  33000],\n",
              "       [    35,  58000],\n",
              "       [    47,  23000],\n",
              "       [    26,  32000],\n",
              "       [    32, 135000],\n",
              "       [    60,  34000],\n",
              "       [    52,  21000],\n",
              "       [    38,  55000],\n",
              "       [    25,  90000],\n",
              "       [    58,  38000],\n",
              "       [    49,  88000],\n",
              "       [    37,  78000],\n",
              "       [    35,  77000],\n",
              "       [    34,  43000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHQsdkieQ3MO"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngio3J4RRr27",
        "outputId": "114302b7-cda6-417d-c8d8-37d0775a189f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr_library = LogisticRegression(verbose=True, penalty='none')\n",
        "lr_library.fit(X=X_train, y=y_train)\n",
        "y_pred1 = lr_library.predict(X_test)\n",
        "\n",
        "print(lr_library.coef_)\n",
        "print(classification_report(y_test, y_pred1))\n",
        "\n",
        "confusion_matrix(y_test, y_pred1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.47691272e-01 4.56688937e-05]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        58\n",
            "           1       0.84      0.76      0.80        42\n",
            "\n",
            "    accuracy                           0.84       100\n",
            "   macro avg       0.84      0.83      0.83       100\n",
            "weighted avg       0.84      0.84      0.84       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52,  6],\n",
              "       [10, 32]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3x5oXSmR0fl",
        "outputId": "4e2f500c-529e-4dc3-8ae2-b782b9d5a111"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        58\n",
            "           1       0.84      0.76      0.80        42\n",
            "\n",
            "    accuracy                           0.84       100\n",
            "   macro avg       0.84      0.83      0.83       100\n",
            "weighted avg       0.84      0.84      0.84       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52,  6],\n",
              "       [10, 32]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8mBf2bmR7AF"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgM-06iSCnf"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q79QWqpSEjl"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lKkxqYQSMaH"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chH8QqNT1lR"
      },
      "source": [
        "#### LOGISTIC REGRESSION WITHOUT LIBRARY"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13bIlXmdUVAP"
      },
      "source": [
        "import math\n",
        "import random\n",
        "class LogisticRegression2:\n",
        "  learning_rate= None\n",
        "  X = None\n",
        "  Y = None\n",
        "  m = None # training smaples\n",
        "  n = None # Number of training features\n",
        "  iterations = None\n",
        "  W = None\n",
        "  b = None\n",
        "  loss = None\n",
        "  loss_bias = None\n",
        "  lce = None\n",
        "\n",
        "  def __init__(self, learning_rate=0.00001, iterations=10000):\n",
        "    self.learning_rate=learning_rate\n",
        "    self.iterations = iterations\n",
        "\n",
        "  def initialise_parameters(self):\n",
        "      self.W = np.zeros(self.n)\n",
        "      self.W = np.random.uniform(-1, 1, self.n)\n",
        "      self.b = 0\n",
        "      print(self.m, self.n, self.W, self.b)\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    x = -1*x\n",
        "    e = np.exp(x)\n",
        "    return 1/(1+e)\n",
        "    \n",
        "  def predict_prob(self, X):\n",
        "      return self.sigmoid(np.dot(X, self.W)+self.b)\n",
        "    \n",
        "  def predict(self, X, threshold=0.5):\n",
        "      return self.predict_prob(X) >= threshold\n",
        "\n",
        "\n",
        "  def fit(self,X,Y):\n",
        "      self.X = X\n",
        "      self.Y = Y\n",
        "      self.m, self.n = X.shape #if len(X.shape)>1 else X.shape[0],1\n",
        "\n",
        "      self.initialise_parameters()\n",
        "      print(self.X.T.shape)\n",
        "      print(self.W.shape)\n",
        "\n",
        "      for i in range( self.iterations ) :\n",
        "          h = self.predict_prob(X)\n",
        "          error = h-self.Y\n",
        "          gradient_w = np.dot(X.T, error) / self.m\n",
        "          gradient_b = np.dot(np.ones(self.Y.shape).T,error) / self.m\n",
        "\n",
        "          self.W -= self.learning_rate * gradient_w\n",
        "          self.b -= self.learning_rate * gradient_b\n",
        "          \n",
        "          if i%1000==0:   \n",
        "            print(\"Iteration \",i, \"W:\",self.W,\", b:\",self.b) \n",
        "          # self.update_weights()\n",
        "      return self\n",
        "  "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3CPZOkvUl3s",
        "outputId": "a17b928e-4955-4d19-961b-a71dae01b855"
      },
      "source": [
        "lr2 = LogisticRegression2(learning_rate=0.01, iterations=100000)\n",
        "lr2.fit(X=X_train, Y=y_train)\n",
        "y_pred2 = lr2.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred2))\n",
        "\n",
        "confusion_matrix(y_test, y_pred2)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 2 [-0.97574916 -0.25534129] 0\n",
            "(2, 300)\n",
            "(2,)\n",
            "Iteration  0 W: [ -0.82218249 297.74465871] , b: 0.0033666666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration  1000 W: [ -7.68591582 275.34465871] , b: -0.9499666666666831\n",
            "Iteration  2000 W: [-14.48631544 291.91165771] , b: -1.901833321720941\n",
            "Iteration  3000 W: [-21.35004877 269.51165771] , b: -2.855166655054319\n",
            "Iteration  4000 W: [-28.2137821  247.11165771] , b: -3.808499988387709\n",
            "Iteration  5000 W: [-35.04035031 244.5773124 ] , b: -4.760966699521099\n",
            "Iteration  6000 W: [-41.90408364 222.1773124 ] , b: -5.714300032854489\n",
            "Iteration  7000 W: [-48.76781698 199.7773124 ] , b: -6.667633366187879\n",
            "Iteration  8000 W: [-55.63155031 177.3773124 ] , b: -7.620966699521269\n",
            "Iteration  9000 W: [-62.49528364 154.9773124 ] , b: -8.574300032854659\n",
            "Iteration  10000 W: [-69.22283424 257.31932137] , b: -9.524200525284211\n",
            "Iteration  11000 W: [-76.0566678  250.15251392] , b: -10.476867196805765\n",
            "Iteration  12000 W: [-82.92040114 227.75251392] , b: -11.430200530139155\n",
            "Iteration  13000 W: [-89.78413447 205.35251392] , b: -12.383533863472545\n",
            "Iteration  14000 W: [-96.61860794 197.79909982] , b: -13.336213866257491\n",
            "Iteration  15000 W: [-103.48234127  175.39909982] , b: -14.289547199590881\n",
            "Iteration  16000 W: [-110.32704127  161.96576649] , b: -15.242480532924272\n",
            "Iteration  17000 W: [-117.1907746   139.56576649] , b: -16.195813866257456\n",
            "Iteration  18000 W: [-124.05450794  117.16576649] , b: -17.149147199589837\n",
            "Iteration  19000 W: [-130.89920794  103.73243315] , b: -18.10208053292222\n",
            "Iteration  20000 W: [-137.76294127   81.33243315] , b: -19.0554138662546\n",
            "Iteration  21000 W: [-144.6266746    58.93243315] , b: -20.00874719958698\n",
            "Iteration  22000 W: [-151.4703083    46.09889267] , b: -20.96164721109446\n",
            "Iteration  23000 W: [-158.42885164 -283.34542326] , b: -21.917946458606103\n",
            "Iteration  24000 W: [-165.29258498 -305.74542326] , b: -22.871279791938484\n",
            "Iteration  25000 W: [-172.11915164 -308.2787566 ] , b: -23.823746458604198\n",
            "Iteration  26000 W: [-178.98288498 -330.6787566 ] , b: -24.77707979193658\n",
            "Iteration  27000 W: [-185.69845704 -218.13388516] , b: -25.7267190584913\n",
            "Iteration  28000 W: [-192.51342371 -212.50055619] , b: -26.678952391998376\n",
            "Iteration  29000 W: [-199.33999038 -215.03388952] , b: -27.63141905866409\n",
            "Iteration  30000 W: [-206.20372371 -237.43388952] , b: -28.58475239199647\n",
            "Iteration  31000 W: [-212.96306741 -177.7136623 ] , b: -29.535452696788646\n",
            "Iteration  32000 W: [-219.82680074 -200.1136623 ] , b: -30.488786030121027\n",
            "Iteration  33000 W: [-226.55296741  -95.78032896] , b: -31.438652696786736\n",
            "Iteration  34000 W: [-233.40960074 -115.1136623 ] , b: -32.391852696786614\n",
            "Iteration  35000 W: [-240.23616741 -117.64699563] , b: -33.344319363454346\n",
            "Iteration  36000 W: [-247.09990074 -140.04699563] , b: -34.297652696788745\n",
            "Iteration  37000 W: [-253.84213408  -79.58032896] , b: -35.24808603012315\n",
            "Iteration  38000 W: [-260.63233408  -54.08032896] , b: -36.19968603012421\n",
            "Iteration  39000 W: [-267.43273408  -37.5136623 ] , b: -37.151552696791946\n",
            "Iteration  40000 W: [-274.27743408  -50.94699563] , b: -38.104486030126345\n",
            "Iteration  41000 W: [-281.13766741  -71.9136623 ] , b: -39.057752696794076\n",
            "Iteration  42000 W: [-287.99430074  -91.24699563] , b: -40.010952696795144\n",
            "Iteration  43000 W: [-294.84456741 -222.88032896] , b: -40.96441936346286\n",
            "Iteration  44000 W: [-301.70830074 -245.28032896] , b: -41.91775269679726\n",
            "Iteration  45000 W: [-308.51810074 -236.54699563] , b: -42.86988603013165\n",
            "Iteration  46000 W: [-315.31850074 -219.98032896] , b: -43.821752696799386\n",
            "Iteration  47000 W: [-321.95716868  -76.41438778] , b: -44.76958605604388\n",
            "Iteration  48000 W: [-328.80343535  -90.68105445] , b: -45.72255272271161\n",
            "Iteration  49000 W: [-335.54500201  -38.41438778] , b: -46.67308605604601\n",
            "Iteration  50000 W: [-342.32196868   -8.54772111] , b: -47.624419389380414\n",
            "Iteration  51000 W: [-349.12263535 -143.28105445] , b: -48.57681938938148\n",
            "Iteration  52000 W: [-355.92196868 -127.21438778] , b: -49.52868605604921\n",
            "Iteration  53000 W: [-362.79613102 -305.86792091] , b: -50.482819234871386\n",
            "Iteration  54000 W: [-369.26179769  203.13207909] , b: -51.426085901539125\n",
            "Iteration  55000 W: [-376.04473102  227.83207909] , b: -52.37758590154019\n",
            "Iteration  56000 W: [-383.07949769 -290.26792091] , b: -53.33591923487459\n",
            "Iteration  57000 W: [-389.80689769 -225.93458757] , b: -54.28605256820899\n",
            "Iteration  58000 W: [-396.46153077  -74.90106826] , b: -55.23425256338892\n",
            "Iteration  59000 W: [-403.24463077  -46.33440159] , b: -56.185719230056655\n",
            "Iteration  60000 W: [-410.08933077  -59.76773493] , b: -57.138652563391055\n",
            "Iteration  61000 W: [-416.73476411  144.66559841] , b: -58.08658589672546\n",
            "Iteration  62000 W: [-423.5304954   162.36721502] , b: -59.03838581164138\n",
            "Iteration  63000 W: [-430.28976206  191.26721532] , b: -59.98921914496449\n",
            "Iteration  64000 W: [-437.28342873 -336.66611802] , b: -60.946619144965545\n",
            "Iteration  65000 W: [-444.06282873 -322.89945125] , b: -61.89801914496178\n",
            "Iteration  66000 W: [-450.83956206 -296.33278458] , b: -62.84941914496285\n",
            "Iteration  67000 W: [-457.60289497 -263.73254305] , b: -63.80048580307669\n",
            "Iteration  68000 W: [-464.33216164 -193.69920955] , b: -64.7505524697413\n",
            "Iteration  69000 W: [-470.88442831   73.06745408] , b: -65.6961191364636\n",
            "Iteration  70000 W: [-477.66625424  -32.23495217] , b: -66.64792546607566\n",
            "Iteration  71000 W: [-484.24365426  167.59836377] , b: -67.59429213336735\n",
            "Iteration  72000 W: [-491.17675426 -284.36830289] , b: -68.55025880003812\n",
            "Iteration  73000 W: [-497.65817754   60.4271228 ] , b: -69.49412359559516\n",
            "Iteration  74000 W: [-504.33954421  226.39378947] , b: -70.44285692893261\n",
            "Iteration  75000 W: [-511.02059485   94.20338169] , b: -71.39231236151521\n",
            "Iteration  76000 W: [-517.84893048 -256.07512936] , b: -72.34558741908108\n",
            "Iteration  77000 W: [-524.51183048 -154.90846025] , b: -73.2943207523508\n",
            "Iteration  78000 W: [-531.31783048 -142.70846025] , b: -74.24632075235493\n",
            "Iteration  79000 W: [-537.95976381   15.45820641] , b: -75.19425408569238\n",
            "Iteration  80000 W: [-544.38453285  256.35492075] , b: -76.13705415140987\n",
            "Iteration  81000 W: [-551.17973285   61.68825408] , b: -77.08932081808065\n",
            "Iteration  82000 W: [-557.91613285  113.48825408] , b: -78.03972081808476\n",
            "Iteration  83000 W: [-564.70618215 -109.71082256] , b: -78.99191453923376\n",
            "Iteration  84000 W: [-571.53774882 -331.87748922] , b: -79.94514787257121\n",
            "Iteration  85000 W: [-578.31528215 -303.44415589] , b: -80.89651453924199\n",
            "Iteration  86000 W: [-584.9464171  -160.67929196] , b: -81.84421458547017\n",
            "Iteration  87000 W: [-591.54785044    2.52070804] , b: -82.79121458547428\n",
            "Iteration  88000 W: [-598.3550171    8.8873747] , b: -83.74328125214507\n",
            "Iteration  89000 W: [-605.0439171   112.05404137] , b: -84.69231458548252\n",
            "Iteration  90000 W: [-611.73535044  210.62070804] , b: -85.64148125215331\n",
            "Iteration  91000 W: [-618.4624171   283.22070804] , b: -86.59148125215744\n",
            "Iteration  92000 W: [-625.53388377 -318.4126253 ] , b: -87.55094791882823\n",
            "Iteration  93000 W: [-632.13455044 -155.4126253 ] , b: -88.49794791883234\n",
            "Iteration  94000 W: [-638.64025044  178.12070804] , b: -89.44264791883643\n",
            "Iteration  95000 W: [-645.4103171   213.62070804] , b: -90.39381458550722\n",
            "Iteration  96000 W: [-652.1428171  268.6873747] , b: -91.34411458551133\n",
            "Iteration  97000 W: [-659.27145044 -378.64595863] , b: -92.30498125218213\n",
            "Iteration  98000 W: [-665.98942132 -319.00499018] , b: -93.25507733639604\n",
            "Iteration  99000 W: [-672.74935465 -284.47165685] , b: -94.20611066973349\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        58\n",
            "           1       0.42      1.00      0.59        42\n",
            "\n",
            "    accuracy                           0.42       100\n",
            "   macro avg       0.21      0.50      0.30       100\n",
            "weighted avg       0.18      0.42      0.25       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 58],\n",
              "       [ 0, 42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZlVx5zSU7fY",
        "outputId": "5fbb580b-d54f-4d17-864f-1f1c5a5b87ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr2.predict_prob(X_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3ZiDbhUssq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzvmjxS9Uxhk",
        "outputId": "e04224c2-f2dd-4bf5-fa31-e0454d2d5ca1"
      },
      "source": [
        "y_pred_2 = lr_wo_library.predict(X_test)\n",
        "y_pred_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFJiGMqWGUt"
      },
      "source": [
        "class LogisticRegression3:\n",
        "    verbose = True\n",
        "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
        "        self.lr = lr\n",
        "        self.num_iter = num_iter\n",
        "        self.fit_intercept = fit_intercept\n",
        "    \n",
        "    def __add_intercept(self, X):\n",
        "        intercept = np.ones((X.shape[0], 1))\n",
        "        return np.concatenate((intercept, X), axis=1)\n",
        "    \n",
        "    def __sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "  \n",
        "    def __loss(self, h, y):\n",
        "        print(y[0],h[0])\n",
        "        n = (-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
        "        # print(n.shape)\n",
        "        # print(\"n : \",n,\"loss - n.mean() : \",n.mean())\n",
        "        return n.mean()\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "        \n",
        "        # weights initialization\n",
        "        self.theta = np.zeros(X.shape[1])\n",
        "        \n",
        "        for i in range(self.num_iter):\n",
        "            z = np.dot(X, self.theta)\n",
        "            h = self.__sigmoid(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / y.size\n",
        "            self.theta -= self.lr * gradient\n",
        "            \n",
        "            if(self.verbose == True and i%50==0):\n",
        "                print(\"Iteration \",i, \"W:\",self.theta) \n",
        "                z = np.dot(X, self.theta)\n",
        "                h = self.__sigmoid(z)\n",
        "                print(f'loss: {self.__loss(h, y)} \\t')\n",
        "    \n",
        "    def predict_prob(self, X):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "    \n",
        "        return self.__sigmoid(np.dot(X, self.theta))\n",
        "    \n",
        "    def predict(self, X, threshold):\n",
        "        return self.predict_prob(X) >= threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lajgc4xZ-EF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kasqpn1FYSgi"
      },
      "source": [
        "lr3 = LogisticRegression3(num_iter = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2i3XtpuYUHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd1c6f9-e1e2-4557-aad4-f628d5587ba4"
      },
      "source": [
        "lr3.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration  0 W: [-1.63333333e-03 -3.21166667e-02 -4.69333333e+01]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  50 W: [-5.3300e-02 -5.2385e-01 -3.2400e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  100 W: [-0.09496667 -0.64421667 88.8       ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  150 W: [-1.46633333e-01 -1.13595000e+00 -1.88266667e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  200 W: [-1.88300000e-01 -1.25631667e+00  2.24533333e+02]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  250 W: [ -0.23996667  -1.74805    -52.53333333]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  300 W: [-2.91633333e-01 -2.23978333e+00 -3.29600000e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  350 W: [-0.3333  -2.36015 83.2    ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  400 W: [  -0.38496667   -2.85188333 -193.86666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  450 W: [ -0.42663333  -2.97225    218.93333333]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  500 W: [ -0.4783      -3.46398333 -58.13333333]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  550 W: [  -0.52996667   -3.95571667 -335.2       ]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  600 W: [-0.57163333 -4.07608333 77.6       ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  650 W: [  -0.6233       -4.56781667 -199.46666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  700 W: [ -0.66496667  -4.68818333 213.33333333]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  750 W: [ -0.71663333  -5.17991667 -63.73333333]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  800 W: [  -0.7683    -5.67165 -340.8    ]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  850 W: [-0.80996667 -5.79201667 72.        ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  900 W: [  -0.86163333   -6.28375    -205.06666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  950 W: [ -0.9033      -6.40411667 207.73333333]\n",
            "0 1.0\n",
            "loss: inf \t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqaefpInYXJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c0c48e-ed1e-48fe-c5e7-da6fe0b87d20"
      },
      "source": [
        "y_pred_3 = lr3.predict(X_test, threshold=0.5)\n",
        "y_pred_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbq6AskYmhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f6a897-4635-4118-cf56-cb3b66bbfcfd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 58],\n",
              "       [ 0, 42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIi6_UjOYvra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}