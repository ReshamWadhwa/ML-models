{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNy9n6sGsS/0EJVj1nvtDh2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReshamWadhwa/ML-models/blob/main/src/models/logistic_regression/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46iBY6dPOzv"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX1_zEpoQBKs",
        "outputId": "ea16cc1a-3f27-4595-abb2-9f3f01db3bd3"
      },
      "source": [
        "data = pd.read_csv(\"suv_data.csv\")\n",
        "data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KcewxFVHQEnP",
        "outputId": "3182aad3-722b-46b9-a377-b0921717f542"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>Female</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510    Male   19            19000          0\n",
              "1  15810944    Male   35            20000          0\n",
              "2  15668575  Female   26            43000          0\n",
              "3  15603246  Female   27            57000          0\n",
              "4  15804002    Male   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZOypBXXRBLA"
      },
      "source": [
        "\n",
        "data = pd.concat([data, pd.get_dummies(data['Gender'], drop_first=True, prefix=\"gender\")], 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qSDRovIcRjac",
        "outputId": "37393c1d-282c-4f76-81bc-07dc3a0bc8b5"
      },
      "source": [
        "data.drop('User ID', axis = 1, inplace = True)\n",
        "data.describe()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "      <th>gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>37.655000</td>\n",
              "      <td>69742.500000</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.482877</td>\n",
              "      <td>34096.960282</td>\n",
              "      <td>0.479864</td>\n",
              "      <td>0.500526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>29.750000</td>\n",
              "      <td>43000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>70000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>46.000000</td>\n",
              "      <td>88000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>150000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age  EstimatedSalary   Purchased  gender_Male\n",
              "count  400.000000       400.000000  400.000000   400.000000\n",
              "mean    37.655000     69742.500000    0.357500     0.490000\n",
              "std     10.482877     34096.960282    0.479864     0.500526\n",
              "min     18.000000     15000.000000    0.000000     0.000000\n",
              "25%     29.750000     43000.000000    0.000000     0.000000\n",
              "50%     37.000000     70000.000000    0.000000     0.000000\n",
              "75%     46.000000     88000.000000    1.000000     1.000000\n",
              "max     60.000000    150000.000000    1.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN7ABcTrQFPl"
      },
      "source": [
        "# X = data[['Age','EstimatedSalary','gender_Male']]\n",
        "X = data.iloc[:,[1,2]].values\n",
        "Y = data['Purchased']\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size = 0.25, random_state = 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRfy4CLPQyzB",
        "outputId": "b20bed10-cfbc-4587-ffad-614af0b54684"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    20,  49000],\n",
              "       [    46,  88000],\n",
              "       [    31,  34000],\n",
              "       [    47,  30000],\n",
              "       [    35,  50000],\n",
              "       [    39,  96000],\n",
              "       [    33, 113000],\n",
              "       [    49,  86000],\n",
              "       [    45,  79000],\n",
              "       [    44,  39000],\n",
              "       [    41,  59000],\n",
              "       [    42,  53000],\n",
              "       [    35,  73000],\n",
              "       [    41,  72000],\n",
              "       [    27,  96000],\n",
              "       [    30, 116000],\n",
              "       [    41,  52000],\n",
              "       [    41,  52000],\n",
              "       [    20,  82000],\n",
              "       [    46,  41000],\n",
              "       [    27,  31000],\n",
              "       [    35,  71000],\n",
              "       [    49,  28000],\n",
              "       [    35,  91000],\n",
              "       [    37,  75000],\n",
              "       [    32, 117000],\n",
              "       [    36,  75000],\n",
              "       [    20,  86000],\n",
              "       [    38,  50000],\n",
              "       [    49,  36000],\n",
              "       [    40,  65000],\n",
              "       [    37,  77000],\n",
              "       [    60,  46000],\n",
              "       [    48, 138000],\n",
              "       [    40,  71000],\n",
              "       [    36,  63000],\n",
              "       [    26,  81000],\n",
              "       [    33,  31000],\n",
              "       [    41,  51000],\n",
              "       [    46,  74000],\n",
              "       [    18,  82000],\n",
              "       [    37,  33000],\n",
              "       [    35,  53000],\n",
              "       [    28,  59000],\n",
              "       [    37,  71000],\n",
              "       [    18,  44000],\n",
              "       [    38,  61000],\n",
              "       [    35,  65000],\n",
              "       [    31,  66000],\n",
              "       [    47,  25000],\n",
              "       [    42, 104000],\n",
              "       [    19,  19000],\n",
              "       [    21,  72000],\n",
              "       [    28,  32000],\n",
              "       [    52, 150000],\n",
              "       [    53, 104000],\n",
              "       [    25,  80000],\n",
              "       [    26,  72000],\n",
              "       [    26,  15000],\n",
              "       [    40, 142000],\n",
              "       [    35,  38000],\n",
              "       [    57, 122000],\n",
              "       [    41,  87000],\n",
              "       [    24,  89000],\n",
              "       [    37,  52000],\n",
              "       [    35, 108000],\n",
              "       [    32, 100000],\n",
              "       [    35, 147000],\n",
              "       [    19,  26000],\n",
              "       [    46,  82000],\n",
              "       [    47, 105000],\n",
              "       [    45,  45000],\n",
              "       [    38,  51000],\n",
              "       [    37,  93000],\n",
              "       [    29,  43000],\n",
              "       [    41,  30000],\n",
              "       [    40,  60000],\n",
              "       [    27,  88000],\n",
              "       [    27,  90000],\n",
              "       [    39,  71000],\n",
              "       [    23,  28000],\n",
              "       [    51, 146000],\n",
              "       [    23,  63000],\n",
              "       [    37,  80000],\n",
              "       [    40,  47000],\n",
              "       [    48,  29000],\n",
              "       [    35,  59000],\n",
              "       [    26,  30000],\n",
              "       [    39, 106000],\n",
              "       [    28,  84000],\n",
              "       [    59,  76000],\n",
              "       [    40,  57000],\n",
              "       [    35,  97000],\n",
              "       [    26,  86000],\n",
              "       [    41,  63000],\n",
              "       [    29,  47000],\n",
              "       [    26,  17000],\n",
              "       [    58,  23000],\n",
              "       [    30,  62000],\n",
              "       [    25,  33000],\n",
              "       [    59,  29000],\n",
              "       [    28,  37000],\n",
              "       [    39,  77000],\n",
              "       [    47, 107000],\n",
              "       [    52, 138000],\n",
              "       [    29,  43000],\n",
              "       [    27, 137000],\n",
              "       [    24,  55000],\n",
              "       [    40,  72000],\n",
              "       [    21,  16000],\n",
              "       [    57,  26000],\n",
              "       [    30, 135000],\n",
              "       [    48, 119000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    28,  44000],\n",
              "       [    37,  74000],\n",
              "       [    35,  27000],\n",
              "       [    37,  79000],\n",
              "       [    32, 120000],\n",
              "       [    29,  75000],\n",
              "       [    30,  17000],\n",
              "       [    25,  79000],\n",
              "       [    40, 107000],\n",
              "       [    24,  19000],\n",
              "       [    41,  72000],\n",
              "       [    38,  61000],\n",
              "       [    36, 144000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    48,  30000],\n",
              "       [    23,  20000],\n",
              "       [    55, 130000],\n",
              "       [    29, 148000],\n",
              "       [    42,  65000],\n",
              "       [    27,  54000],\n",
              "       [    37,  55000],\n",
              "       [    25,  22000],\n",
              "       [    59, 143000],\n",
              "       [    42,  54000],\n",
              "       [    27,  17000],\n",
              "       [    47,  49000],\n",
              "       [    28,  59000],\n",
              "       [    33,  69000],\n",
              "       [    31,  68000],\n",
              "       [    35,  23000],\n",
              "       [    35,  22000],\n",
              "       [    57,  33000],\n",
              "       [    30, 107000],\n",
              "       [    46,  23000],\n",
              "       [    41,  60000],\n",
              "       [    33,  41000],\n",
              "       [    33,  60000],\n",
              "       [    47,  47000],\n",
              "       [    28,  55000],\n",
              "       [    45,  32000],\n",
              "       [    35,  75000],\n",
              "       [    59,  42000],\n",
              "       [    47,  50000],\n",
              "       [    47,  51000],\n",
              "       [    35,  79000],\n",
              "       [    39,  42000],\n",
              "       [    40,  78000],\n",
              "       [    23,  48000],\n",
              "       [    39,  75000],\n",
              "       [    35,  57000],\n",
              "       [    55,  39000],\n",
              "       [    31,  71000],\n",
              "       [    28, 123000],\n",
              "       [    42,  80000],\n",
              "       [    40,  59000],\n",
              "       [    48,  74000],\n",
              "       [    21,  88000],\n",
              "       [    53,  72000],\n",
              "       [    27,  58000],\n",
              "       [    35,  47000],\n",
              "       [    28,  89000],\n",
              "       [    26,  80000],\n",
              "       [    32, 117000],\n",
              "       [    42,  75000],\n",
              "       [    33, 149000],\n",
              "       [    41,  80000],\n",
              "       [    31,  58000],\n",
              "       [    39, 134000],\n",
              "       [    27,  20000],\n",
              "       [    29,  83000],\n",
              "       [    19,  70000],\n",
              "       [    19,  85000],\n",
              "       [    29,  61000],\n",
              "       [    39, 134000],\n",
              "       [    31,  76000],\n",
              "       [    41,  72000],\n",
              "       [    26,  80000],\n",
              "       [    40,  61000],\n",
              "       [    35,  25000],\n",
              "       [    48,  96000],\n",
              "       [    42, 149000],\n",
              "       [    28,  79000],\n",
              "       [    51, 134000],\n",
              "       [    33,  28000],\n",
              "       [    42,  54000],\n",
              "       [    45,  22000],\n",
              "       [    37,  57000],\n",
              "       [    34, 112000],\n",
              "       [    35,  39000],\n",
              "       [    22,  27000],\n",
              "       [    35,  72000],\n",
              "       [    39,  59000],\n",
              "       [    20,  74000],\n",
              "       [    46,  32000],\n",
              "       [    26,  43000],\n",
              "       [    29,  83000],\n",
              "       [    55, 125000],\n",
              "       [    37, 146000],\n",
              "       [    45, 131000],\n",
              "       [    33,  43000],\n",
              "       [    41,  45000],\n",
              "       [    42,  79000],\n",
              "       [    37, 137000],\n",
              "       [    24,  84000],\n",
              "       [    32,  18000],\n",
              "       [    56, 104000],\n",
              "       [    49,  39000],\n",
              "       [    28,  85000],\n",
              "       [    53, 143000],\n",
              "       [    30,  89000],\n",
              "       [    57,  60000],\n",
              "       [    40,  75000],\n",
              "       [    41,  79000],\n",
              "       [    20,  82000],\n",
              "       [    22,  55000],\n",
              "       [    35,  88000],\n",
              "       [    54,  70000],\n",
              "       [    31,  15000],\n",
              "       [    50,  36000],\n",
              "       [    42,  65000],\n",
              "       [    34,  43000],\n",
              "       [    42, 108000],\n",
              "       [    54,  26000],\n",
              "       [    19,  21000],\n",
              "       [    36,  50000],\n",
              "       [    37,  70000],\n",
              "       [    36, 126000],\n",
              "       [    47,  20000],\n",
              "       [    30,  79000],\n",
              "       [    59,  83000],\n",
              "       [    29,  80000],\n",
              "       [    43, 112000],\n",
              "       [    38,  80000],\n",
              "       [    58, 144000],\n",
              "       [    36, 125000],\n",
              "       [    49,  28000],\n",
              "       [    18,  52000],\n",
              "       [    30,  15000],\n",
              "       [    59,  88000],\n",
              "       [    27,  57000],\n",
              "       [    38,  71000],\n",
              "       [    31,  89000],\n",
              "       [    47,  34000],\n",
              "       [    31,  74000],\n",
              "       [    37,  72000],\n",
              "       [    40,  57000],\n",
              "       [    59, 130000],\n",
              "       [    49,  65000],\n",
              "       [    48,  90000],\n",
              "       [    46,  22000],\n",
              "       [    54, 104000],\n",
              "       [    35,  20000],\n",
              "       [    49, 141000],\n",
              "       [    48,  41000],\n",
              "       [    35,  55000],\n",
              "       [    36,  60000],\n",
              "       [    32, 150000],\n",
              "       [    18,  68000],\n",
              "       [    24,  55000],\n",
              "       [    42,  90000],\n",
              "       [    38,  59000],\n",
              "       [    60, 108000],\n",
              "       [    22,  63000],\n",
              "       [    24,  32000],\n",
              "       [    46,  59000],\n",
              "       [    48, 134000],\n",
              "       [    41,  72000],\n",
              "       [    50,  44000],\n",
              "       [    38,  71000],\n",
              "       [    24,  23000],\n",
              "       [    35,  61000],\n",
              "       [    37,  80000],\n",
              "       [    24,  27000],\n",
              "       [    26,  84000],\n",
              "       [    34,  25000],\n",
              "       [    36,  54000],\n",
              "       [    21,  68000],\n",
              "       [    41,  71000],\n",
              "       [    60,  42000],\n",
              "       [    52,  90000],\n",
              "       [    20,  23000],\n",
              "       [    51,  23000],\n",
              "       [    46,  79000],\n",
              "       [    30,  49000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "927rMMzdQzed",
        "outputId": "44ed8ca1-ef55-4127-9123-65a636e6b400"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    36,  33000],\n",
              "       [    39,  61000],\n",
              "       [    36, 118000],\n",
              "       [    39, 122000],\n",
              "       [    26, 118000],\n",
              "       [    38,  65000],\n",
              "       [    20,  36000],\n",
              "       [    49,  89000],\n",
              "       [    31,  18000],\n",
              "       [    48, 141000],\n",
              "       [    34,  72000],\n",
              "       [    39,  73000],\n",
              "       [    35,  72000],\n",
              "       [    48, 131000],\n",
              "       [    53,  82000],\n",
              "       [    56, 133000],\n",
              "       [    60,  83000],\n",
              "       [    27,  58000],\n",
              "       [    28,  87000],\n",
              "       [    60, 102000],\n",
              "       [    40,  75000],\n",
              "       [    50,  88000],\n",
              "       [    44, 139000],\n",
              "       [    47,  43000],\n",
              "       [    45,  26000],\n",
              "       [    26,  15000],\n",
              "       [    58,  47000],\n",
              "       [    49,  74000],\n",
              "       [    53,  34000],\n",
              "       [    52, 114000],\n",
              "       [    39,  42000],\n",
              "       [    19,  76000],\n",
              "       [    18,  86000],\n",
              "       [    57,  74000],\n",
              "       [    27,  84000],\n",
              "       [    30,  80000],\n",
              "       [    22,  18000],\n",
              "       [    32,  86000],\n",
              "       [    50,  20000],\n",
              "       [    19,  25000],\n",
              "       [    47, 144000],\n",
              "       [    58, 101000],\n",
              "       [    34, 115000],\n",
              "       [    23,  66000],\n",
              "       [    56,  60000],\n",
              "       [    31, 118000],\n",
              "       [    48,  35000],\n",
              "       [    47, 113000],\n",
              "       [    39,  79000],\n",
              "       [    52,  38000],\n",
              "       [    24,  58000],\n",
              "       [    37,  53000],\n",
              "       [    42,  80000],\n",
              "       [    46,  28000],\n",
              "       [    42,  73000],\n",
              "       [    37,  62000],\n",
              "       [    60,  42000],\n",
              "       [    36,  52000],\n",
              "       [    58,  95000],\n",
              "       [    43, 129000],\n",
              "       [    27,  89000],\n",
              "       [    23,  82000],\n",
              "       [    38, 112000],\n",
              "       [    35,  50000],\n",
              "       [    36,  99000],\n",
              "       [    37, 144000],\n",
              "       [    26,  35000],\n",
              "       [    42,  70000],\n",
              "       [    43, 133000],\n",
              "       [    38,  50000],\n",
              "       [    46,  96000],\n",
              "       [    35,  44000],\n",
              "       [    38, 113000],\n",
              "       [    39,  71000],\n",
              "       [    26,  52000],\n",
              "       [    54, 108000],\n",
              "       [    33,  51000],\n",
              "       [    26,  16000],\n",
              "       [    30,  87000],\n",
              "       [    35,  60000],\n",
              "       [    29,  28000],\n",
              "       [    45,  22000],\n",
              "       [    46, 117000],\n",
              "       [    32,  18000],\n",
              "       [    22,  81000],\n",
              "       [    25,  87000],\n",
              "       [    48,  33000],\n",
              "       [    35,  58000],\n",
              "       [    47,  23000],\n",
              "       [    26,  32000],\n",
              "       [    32, 135000],\n",
              "       [    60,  34000],\n",
              "       [    52,  21000],\n",
              "       [    38,  55000],\n",
              "       [    25,  90000],\n",
              "       [    58,  38000],\n",
              "       [    49,  88000],\n",
              "       [    37,  78000],\n",
              "       [    35,  77000],\n",
              "       [    34,  43000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHQsdkieQ3MO"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngio3J4RRr27"
      },
      "source": [
        "lr_library = LogisticRegression(verbose=True, penalty='none')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3x5oXSmR0fl",
        "outputId": "e363a15a-d085-4013-e1ec-a5feb64b9fc4"
      },
      "source": [
        "lr_library.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=True,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8mBf2bmR7AF"
      },
      "source": [
        "y_pred = lr_library.predict(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWgM-06iSCnf",
        "outputId": "80d2863a-6c4a-4f70-ff68-6364c73f3d82"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q79QWqpSEjl",
        "outputId": "cf12c057-7a8a-4799-c788-298b1cccebe0"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        58\n",
            "           1       0.84      0.76      0.80        42\n",
            "\n",
            "    accuracy                           0.84       100\n",
            "   macro avg       0.84      0.83      0.83       100\n",
            "weighted avg       0.84      0.84      0.84       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lKkxqYQSMaH",
        "outputId": "c634ec9f-91ca-400e-8163-639240d31207"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52,  6],\n",
              "       [10, 32]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chH8QqNT1lR"
      },
      "source": [
        "#### LOGISTIC REGRESSION WITHOUT LIBRARY"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13bIlXmdUVAP"
      },
      "source": [
        "import math\n",
        "\n",
        "class LogisticRegression_wo_lib:\n",
        "  learning_rate= None\n",
        "  X = None\n",
        "  Y = None\n",
        "  m = None # training smaples\n",
        "  n = None # Number of training features\n",
        "  iterations = None\n",
        "  W = None\n",
        "  b = None\n",
        "  loss = None\n",
        "  loss_bias = None\n",
        "  lce = None\n",
        "\n",
        "  def __init__(self, learning_rate=0.01, iterations=1000):\n",
        "    self.learning_rate=learning_rate\n",
        "    self.iterations = iterations\n",
        "\n",
        "  def initialise_parameters(self):\n",
        "      self.W = np.zeros(self.n)\n",
        "      self.b = 0\n",
        "      print(self.m, self.n, self.W, self.b)\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    x = -1*x\n",
        "    e = np.exp(x)\n",
        "    return 1/(1+e)\n",
        "    \n",
        "  def predict_prob(self, X):\n",
        "      return self.sigmoid(np.dot(X, self.W)+self.b)\n",
        "    \n",
        "  def predict(self, X, threshold=0.1):\n",
        "      return self.predict_prob(X) >= threshold\n",
        "\n",
        "\n",
        "  def fit(self,X,Y):\n",
        "      self.X = X\n",
        "      self.Y = Y\n",
        "      self.m, self.n = X.shape #if len(X.shape)>1 else X.shape[0],1\n",
        "\n",
        "      self.initialise_parameters()\n",
        "      print(self.X.T.shape)\n",
        "      print(self.W.shape)\n",
        "      for i in range( self.iterations ) :\n",
        "        \n",
        "          lin_sum = np.dot(X, self.W)+self.b\n",
        "          h = self.sigmoid(lin_sum)\n",
        "          gradient = np.dot(X.T, (h - Y)) / Y.size\n",
        "\n",
        "          self.W -= self.learning_rate * gradient\n",
        "            \n",
        "          if i%50==0:   \n",
        "            print(\"Iteration \",i, \"W:\",self.W,\", b:\",self.b) \n",
        "          # self.update_weights()\n",
        "      return self\n",
        "  "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3CPZOkvUl3s",
        "outputId": "a462744e-debc-44eb-9cd1-ccbafa6fe87f"
      },
      "source": [
        "lr_wo_library = LogisticRegression_wo_lib()\n",
        "lr_wo_library.fit(X_train,y_train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 2 [0. 0.] 0\n",
            "(2, 300)\n",
            "(2,)\n",
            "Iteration  0 W: [-3.21166667e-02 -4.69333333e+01] , b: 0\n",
            "Iteration  50 W: [  -0.52385 -324.     ] , b: 0\n",
            "Iteration  100 W: [-0.64421667 88.8       ] , b: 0\n",
            "Iteration  150 W: [  -1.13595    -188.26666667] , b: 0\n",
            "Iteration  200 W: [ -1.25631667 224.53333333] , b: 0\n",
            "Iteration  250 W: [ -1.74805    -52.53333333] , b: 0\n",
            "Iteration  300 W: [  -2.23978333 -329.6       ] , b: 0\n",
            "Iteration  350 W: [-2.36015 83.2    ] , b: 0\n",
            "Iteration  400 W: [  -2.85188333 -193.86666667] , b: 0\n",
            "Iteration  450 W: [ -2.97225    218.93333333] , b: 0\n",
            "Iteration  500 W: [ -3.46398333 -58.13333333] , b: 0\n",
            "Iteration  550 W: [  -3.95571667 -335.2       ] , b: 0\n",
            "Iteration  600 W: [-4.07608333 77.6       ] , b: 0\n",
            "Iteration  650 W: [  -4.56781667 -199.46666667] , b: 0\n",
            "Iteration  700 W: [ -4.68818333 213.33333333] , b: 0\n",
            "Iteration  750 W: [ -5.17991667 -63.73333333] , b: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration  800 W: [  -5.67165 -340.8    ] , b: 0\n",
            "Iteration  850 W: [-5.79201667 72.        ] , b: 0\n",
            "Iteration  900 W: [  -6.28375    -205.06666667] , b: 0\n",
            "Iteration  950 W: [ -6.40411667 207.73333333] , b: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.LogisticRegression_wo_lib at 0x7ff611eea510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZlVx5zSU7fY"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3ZiDbhUssq"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzvmjxS9Uxhk",
        "outputId": "e04224c2-f2dd-4bf5-fa31-e0454d2d5ca1"
      },
      "source": [
        "y_pred_2 = lr_wo_library.predict(X_test)\n",
        "y_pred_2"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFJiGMqWGUt"
      },
      "source": [
        "class LogisticRegression3:\n",
        "    verbose = True\n",
        "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
        "        self.lr = lr\n",
        "        self.num_iter = num_iter\n",
        "        self.fit_intercept = fit_intercept\n",
        "    \n",
        "    def __add_intercept(self, X):\n",
        "        intercept = np.ones((X.shape[0], 1))\n",
        "        return np.concatenate((intercept, X), axis=1)\n",
        "    \n",
        "    def __sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "  \n",
        "    def __loss(self, h, y):\n",
        "        print(y[0],h[0])\n",
        "        n = (-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
        "        # print(n.shape)\n",
        "        # print(\"n : \",n,\"loss - n.mean() : \",n.mean())\n",
        "        return n.mean()\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "        \n",
        "        # weights initialization\n",
        "        self.theta = np.zeros(X.shape[1])\n",
        "        \n",
        "        for i in range(self.num_iter):\n",
        "            z = np.dot(X, self.theta)\n",
        "            h = self.__sigmoid(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / y.size\n",
        "            self.theta -= self.lr * gradient\n",
        "            \n",
        "            if(self.verbose == True and i%50==0):\n",
        "                print(\"Iteration \",i, \"W:\",self.theta) \n",
        "                z = np.dot(X, self.theta)\n",
        "                h = self.__sigmoid(z)\n",
        "                print(f'loss: {self.__loss(h, y)} \\t')\n",
        "    \n",
        "    def predict_prob(self, X):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "    \n",
        "        return self.__sigmoid(np.dot(X, self.theta))\n",
        "    \n",
        "    def predict(self, X, threshold):\n",
        "        return self.predict_prob(X) >= threshold"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lajgc4xZ-EF"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kasqpn1FYSgi"
      },
      "source": [
        "lr3 = LogisticRegression3(num_iter = 1000)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2i3XtpuYUHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd1c6f9-e1e2-4557-aad4-f628d5587ba4"
      },
      "source": [
        "lr3.fit(X_train, y_train)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration  0 W: [-1.63333333e-03 -3.21166667e-02 -4.69333333e+01]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  50 W: [-5.3300e-02 -5.2385e-01 -3.2400e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  100 W: [-0.09496667 -0.64421667 88.8       ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  150 W: [-1.46633333e-01 -1.13595000e+00 -1.88266667e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  200 W: [-1.88300000e-01 -1.25631667e+00  2.24533333e+02]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  250 W: [ -0.23996667  -1.74805    -52.53333333]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  300 W: [-2.91633333e-01 -2.23978333e+00 -3.29600000e+02]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  350 W: [-0.3333  -2.36015 83.2    ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  400 W: [  -0.38496667   -2.85188333 -193.86666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  450 W: [ -0.42663333  -2.97225    218.93333333]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  500 W: [ -0.4783      -3.46398333 -58.13333333]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  550 W: [  -0.52996667   -3.95571667 -335.2       ]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  600 W: [-0.57163333 -4.07608333 77.6       ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  650 W: [  -0.6233       -4.56781667 -199.46666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  700 W: [ -0.66496667  -4.68818333 213.33333333]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  750 W: [ -0.71663333  -5.17991667 -63.73333333]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  800 W: [  -0.7683    -5.67165 -340.8    ]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  850 W: [-0.80996667 -5.79201667 72.        ]\n",
            "0 1.0\n",
            "loss: inf \t\n",
            "Iteration  900 W: [  -0.86163333   -6.28375    -205.06666667]\n",
            "0 0.0\n",
            "loss: inf \t\n",
            "Iteration  950 W: [ -0.9033      -6.40411667 207.73333333]\n",
            "0 1.0\n",
            "loss: inf \t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqaefpInYXJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c0c48e-ed1e-48fe-c5e7-da6fe0b87d20"
      },
      "source": [
        "y_pred_3 = lr3.predict(X_test, threshold=0.5)\n",
        "y_pred_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbq6AskYmhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f6a897-4635-4118-cf56-cb3b66bbfcfd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 58],\n",
              "       [ 0, 42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIi6_UjOYvra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}