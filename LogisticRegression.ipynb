{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqNH2M4e6n5EtdZbadDu21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReshamWadhwa/ML-models/blob/main/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL8XkB98PC0v"
      },
      "source": [
        "# Logictic Regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZDJXkd1PM0D"
      },
      "source": [
        " Feature Vector : x = [x_1, x_2, …., x_n]\n",
        "\n",
        " Response vector : y = [y_1, y_2, …., y_n] where all y = 0 or 1\n",
        " \n",
        "    h( x ) = sigmoid(w * x + b  )\n",
        "    \n",
        "   b = bias -- needed\n",
        "\n",
        "   x represents the feature vector\n",
        "   \n",
        "   w represents the weight vector.\n",
        "\n",
        "\n",
        "```\n",
        "sigmoid(z) = 1/(1+e^-z)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2M1lyJvutH9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndj4XTLYvDnJ"
      },
      "source": [
        "**Ques. Why is the bias term added ? bias term = b**\n",
        "\n",
        "**Ans**. For situation when x1=x2=x3 = 0 , our y is forced to be 0.5 (sigmoid of 0 = 0.5) . This might lead to underfit or bias in model if original data fit doesn;t pass through 0 but we force it to do so. Hence to avoid bias wrt the stagnant point 0.5, a bias term is added to the equation and the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZHSsM4VvneD"
      },
      "source": [
        "**Ques. What are the assumptions of a Logistic Regressor?**\n",
        "\n",
        "Ans. Logistic Regression's assumptions about data are listed below along with their reasons.\n",
        "\n",
        "*1. The Response Variable is Binary*\n",
        "\n",
        "  If the target/dependendent/response variable is non binary or continuous, then Logistic Regression won't give meaningful results as the sigmoid function + loss function test the predictions wrt dichotomy of classes\n",
        "\n",
        "*2. Observations are independent of each other*\n",
        "\n",
        "The observations should not come from repeated measurements of the same individual or be related to each other in any way.The dataset should not contain duplicate or repeated values\n",
        "\n",
        "*3. There is No Multicollinearity Among Explanatory Variables*\n",
        "\n",
        "Features shouldn't be dependent on each other.\n",
        "\n",
        "There shouldn't be high correlation between two or more independent variables i.e., X.\n",
        "\n",
        "But why? Because coefficients/weights are reflective of change in that feature only while computing Y. Let say , y = w1a1+w2a2+w3a3+ w0 //(bias)\n",
        "\n",
        "and that a1 and a2 are correlated.\n",
        "\n",
        "Now, model's interpretation of w1 is the change in y caused by a unit change in a1 alone and no other feature, however since a1 and a2 are correlated, this assumption fails.\n",
        "\n",
        "4. There are No Extreme Outliers in the data.\n",
        "\n",
        "5. ASSUMPTION OF LINEARITY OF INDEPENDENT VARIABLES AND LOG ODDS\n",
        "1. Large sample size\n",
        "\n",
        "  \n",
        "1. Linear relationship between observations and their logits\n",
        "\n",
        "    Logit(p)  = log(p / (1-p))\n",
        "    \n",
        "    where p is the probability of success\n",
        "    \n",
        "    also known as a log-odds function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUpNX5T-vfxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}