{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8LgYB8wi1c9u69tWWI0EC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReshamWadhwa/ML-models/blob/main/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL8XkB98PC0v"
      },
      "source": [
        "# Logictic Regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZDJXkd1PM0D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2M1lyJvutH9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZHSsM4VvneD"
      },
      "source": [
        "**Ques. What are the assumptions of a Logistic Regressor?**\n",
        "\n",
        "Ans. Logistic Regression's assumptions about data are listed below along with their reasons.\n",
        "\n",
        "*1. The Response Variable is Binary*\n",
        "```\n",
        "  If the target/dependendent/response variable is non binary or continuous, then Logistic Regression won't give meaningful results as the sigmoid function + loss function test the predictions wrt dichotomy of classes\n",
        "```\n",
        "*2. Observations are independent of each other*\n",
        "```\n",
        "The observations should not come from repeated measurements of the same individual or be related to each other in any way.The dataset should not contain duplicate or repeated values\n",
        "```\n",
        "*3. There is No Multicollinearity Among Explanatory Variables*\n",
        "```\n",
        "Features shouldn't be dependent on each other.\n",
        "\n",
        "There shouldn't be high correlation between two or more independent variables i.e., X.\n",
        "```\n",
        "But why? \n",
        "```\n",
        "Because coefficients/weights are reflective of change in that feature only while computing Y. Let say , y = w1a1+w2a2+w3a3+ w0 //(bias)\n",
        "\n",
        "and that a1 and a2 are correlated.\n",
        "\n",
        "Now, model's interpretation of w1 is the change in y caused by a unit change in a1 alone and no other feature, however since a1 and a2 are correlated, this assumption fails.\n",
        "```\n",
        "\n",
        "4. There are No Extreme Outliers in the data.\n",
        "\n",
        "1. Large sample size\n",
        "\n",
        "1. Linear relationship between observations and their logits\n",
        "```\n",
        "    Logit(p)  = log(p / (1-p))\n",
        "    \n",
        "    where p is the probability of success\n",
        "    \n",
        "    also known as a log-odds function\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1GHmMnQ7gCj"
      },
      "source": [
        "**Question. What is the equation for Logistic Regression?**\n",
        "\n",
        "**Ans.** \n",
        "\n",
        " Feature Vector : x = [x_1, x_2, …., x_n]\n",
        "\n",
        " Response vector : y = [y_1, y_2, …., y_n] where all y = 0 or 1\n",
        " \n",
        "    h( x ) = sigmoid(w * x + b  )\n",
        "    \n",
        "   b = bias -- needed\n",
        "\n",
        "   x represents the feature vector\n",
        "   \n",
        "   w represents the weight vector.\n",
        "\n",
        "\n",
        "```\n",
        "sigmoid(z) = 1/(1+e^-z)\n",
        "```\n",
        "\n",
        "\n",
        "There are two ways to optimize weights in Logistic Regression :\n",
        "\n",
        "1. Least Squares Optimization (iteratively reweighted least squares).\n",
        "1. Maximum Likelihood Estimation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndj4XTLYvDnJ"
      },
      "source": [
        "**Ques. Why is the bias term added ? bias term = b**\n",
        "\n",
        "**Ans**. For situation when x1=x2=x3 = 0 , our y is forced to be 0.5 (sigmoid of 0 = 0.5) . This might lead to underfit or bias in model if original data fit doesn;t pass through 0 but we force it to do so. Hence to avoid bias wrt the stagnant point 0.5, a bias term is added to the equation and the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkcUUb3fviex"
      },
      "source": [
        "**Quess. What is the Least Squares Optimization process to update the weights in Logistic Regression?**\n",
        "\n",
        "**Ans.**  The linear part of the model (the weighted sum of the inputs == wx+b ) calculates the **log-odds** of a successful event, specifically, the log-odds that a sample belongs to class 1.\n",
        "\n",
        "```\n",
        "log-odds = w0+w1x1 + w2x2+....\n",
        "```\n",
        "Odds = Probability of success/probability of failure\n",
        "\n",
        "In Binomial distribution (Two possible outcomes: true or false, success or failure, yes or no), probability of failure = 1- probability of success for one event.\n",
        "\n",
        "hence, \n",
        "\n",
        "```\n",
        "odds = p/(1-p)\n",
        "```\n",
        "\n",
        "Log odds is log of this value == Logit == Logistic Unit\n",
        "\n",
        "```\n",
        "log-odd = log(p/(1-p))\n",
        "```\n",
        "\n",
        "Now, this is the linear part of the Logistic Regression classification . \n",
        "\n",
        "Hence, \n",
        "```\n",
        "log ( p/(1-p) ) = w0+w1x1 + w2x2+....+ wnxn\n",
        "```\n",
        "\n",
        "What we eventually want is p and that can be obtained by taking exponents of log odds. \n",
        "\n",
        "```\n",
        "odds = p/(1-p) = exp ( w0 + w1x1 + w2x2... + wnxn)\n",
        "```\n",
        "\n",
        "Now, odds can be converted into probability as follows \n",
        "```\n",
        "odds = p/(1-p)\n",
        "\n",
        "odds(1-p) = p\n",
        "odds - p*odds = p \n",
        "odds = p+p*odds\n",
        "odds = p(1+odds)\n",
        "Hence, \n",
        "p = odds/(1+odds)\n",
        "\n",
        "\n",
        "p = exp( log_odds ) / ( 1 + exp(log_odds))\n",
        "\n",
        "p = (1/exp(-log_odds)) / (1+ 1/exp(-log_odds)\n",
        "\n",
        "Let log_odds = l\n",
        "\n",
        "p = (1/e(-l) ) / (1+ 1/e(-l) )\n",
        "```\n",
        "\n",
        "Taking 1/e(-l) commom in both numerator and denominator and cancelling, \n",
        "```\n",
        "p = 1/ ( 1+e(-log_odds))\n",
        "\n",
        "``` \n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_2vtrHwzdsi"
      },
      "source": [
        "**Quess. What is the Maximum Likelihood Estimation wrt Logistic Regression?**\n",
        "\n",
        "**Ans.** MLE is a probabilistic framework for estimating the parameters of a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUpNX5T-vfxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}