{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6yPP/gfVGVTaOEZuYVIej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReshamWadhwa/ML-models/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZQXSe8MeP5S"
      },
      "source": [
        "# Linear Regression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmRtDI9zefim"
      },
      "source": [
        "# Feature Vector \n",
        "# x = [x_1, x_2, …., x_n]\n",
        "# REsponse vector\n",
        "# y = [y_1, y_2, …., y_n]\n",
        "\n",
        "#  h( x ) = w * x + b  \n",
        "    \n",
        "#   b = bias -- needed\n",
        "#   x represents the feature vector\n",
        "#   w represents the weight vector.\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02tSlBl4njxF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYun4JI1nm3A"
      },
      "source": [
        "**WHY IS BIAS TERM NEEDED?**\n",
        "\n",
        "When bias is absent\n",
        "\n",
        "y = w1x1+w2x2+w3x3...+wnxn\n",
        "\n",
        "For situation when x1=x2=x3 = 0 , our y is forced to be 0.\n",
        "This might lead to underfit or bias in model if original data fit doesn;t pass through 0 but we force it to do so. \n",
        "Hence to avoid bias wrt origin, a bias term is added to the equation and the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbUnrxNIoEhI"
      },
      "source": [
        "What are the assumptions about data before fitting a Linear Regressor?\n",
        "\n",
        "1. **Data Target variable is continuous (Regression problem).**\n",
        "    \n",
        "    Non continous data require classification model\n",
        "\n",
        "1. **Linear relationship in y and X.**\n",
        "\n",
        "  Relationship between dependent and independent variables is linear. \n",
        "  \n",
        "  The linearity assumption can be tested using scatter plots.\n",
        "\n",
        "  **But Why?** Because Non linear data relationships cannot be captured by sum of scalar matrix multiplications - how LR works\n",
        "\n",
        "1. **Little or no multi-collinearity.**\n",
        "\n",
        "  Features shouldn't be dependent on each other. \n",
        "\n",
        "  There shouldn't be high correlation between two or more independent variables i.e., X. \n",
        "\n",
        "  **But why?** Because coefficients/weights are reflective of change in that feature only while computing Y. \n",
        "  Let say , y = w1a1+w2a2+w3a3+ w0   //(bias)\n",
        "\n",
        "  and  that a1 and a2 are correlated.\n",
        "\n",
        "  Now, model's interpretation of w1 is the change in y caused by a unit change in a1 alone and no other feature, however since a1 and a2 are correlated, this assumption fails.\n",
        "\n",
        "  Can be resolved using VIF ( Variance Inflation Factor )\n",
        "\n",
        "1. **Little or no auto-correlation/Independence of observations.**\n",
        "  \n",
        "    Autocorrelation is when a variable is related to earlier versions of itself. \n",
        "\n",
        "1. **Homoscedasticity**\n",
        "\n",
        "  Homoscedasticity describes a situation in which the error term (that is, the “noise” or random disturbance in the relationship between the independent variables and the dependent variable) is the same across all values of the independent variables. The variance of the residuals is constant.\n",
        "\n",
        "  **But why ?** 10% change in lower value of x will result in lower error than 10% change in x when it is equal to 1,000,000. This is a case when error will have different variance across different range of features.\n",
        "\n",
        "  Can be solved by using Weighted Least Square Model - This type of regression assigns a weight to each data point based on the variance of its fitted value.\n",
        "\n",
        "1. **All independent variables are uncorrelated with the error term**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy8fzv6TsQwi"
      },
      "source": [
        "**Variance inflation factor (VIF)** \n",
        "\n",
        "is used to detect the severity of multicollinearity in the ordinary least square (OLS) regression analysis.\n",
        "\n",
        "\n",
        "Variance Inflation Factors (VIFs) measure the correlation among independent variables in least squares regression models. Statisticians refer to this type of correlation as multicollinearity. Excessive multicollinearity can cause problems for regression models.\n",
        "\n",
        "*Calculating Variance Inflation Factors*\n",
        "\n",
        "VIFs use multiple regression to calculate the degree of multicollinearity. Imagine you have four independent variables: X1, X2, X3, and X4. Of course, the model has a dependent variable (Y), but we don’t need to worry about it for our purposes. When your statistical software calculates VIFs, it uses multiple regression to regress all IVs except one on that final IV. It repeats this process for all IVs, as shown below:\n",
        "\n",
        "X1 ⇐ X2, X3, X4\n",
        "X2 ⇐ X1, X3, X4\n",
        "X3 ⇐ X1, X2, X4\n",
        "X4 ⇐ X1, X2, X3\n",
        "\n",
        "To calculate the VIFs, all independent variables become a dependent variable. Each model produces an R-squared value indicating the percentage of the variance in the individual IV that the set of IVs explains. Consequently, higher R-squared values indicate higher degrees of multicollinearity. VIF calculations use these R-squared values. The VIF for an independent variable equals the following:\n",
        "\n",
        "VIF formula.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGoXwxmlvx8h"
      },
      "source": [
        "\n",
        "**R-squared** = Variance Explained (R2)\n",
        "\n",
        "It records the proportion of variation in the dependent variable explained by the independent variables. \n",
        "In range [0,1] -- 0 means X doesn't explain any variance in Y and hence has no impact at all, 1 means X explains all variation present in Y\n",
        "\n",
        "In case of overfit, R2 will still be high if too many independent features are present . Adjusted R2 considers the nummber of features as well. \n",
        "\n",
        "\n",
        "```\n",
        "Adjusted R Squared = 1 – [((1 – R2) * (n – 1)) / (n – k – 1)]\n",
        "\n",
        "n == data points \n",
        "k == number of independent feature variables\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "Now, in VIF, all independent features are modelled against other IFs. R-squared is coefficient of determination of these individual features. \n",
        "\n",
        "If R-sq of X1 =0 , it means that other features do not explain any of its variance. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUVqjnUAv0yG"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Tolerance of i-th feature= 1- R-squared\n",
        "```\n",
        "\n",
        "i.e., how much variance is left unexplained when using the given features.\n",
        "\n",
        "\n",
        "```\n",
        "VIF of i-th feature = 1/tolerance\n",
        "\n",
        "VIFi = 1/(1-R2)\n",
        "```\n",
        "\n",
        "Higher the explained variance for a coef, lower the tolerance, higher the VIF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGkzFCvzvz8r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sSxM6BTtKJw"
      },
      "source": [
        "The potential solutions include the following:\n",
        "\n",
        "1. Remove some of the highly correlated independent variables.\n",
        "1. Linearly combine the independent variables, such as adding them together.\n",
        "1. Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.\n",
        "1. LASSO and Ridge regression are advanced forms of regression analysis that can handle multicollinearity. If you know how to perform linear least squares regression, you’ll be able to handle these analyses with just a little additional study."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIGl_PIYmA_W"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA9wLdiOl9Ft"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# y = w0 + w1x\n",
        "\n",
        "# Aim is to arrive at w0 , w1 values at which error is minimum.\n",
        "\n",
        "# Error = \n",
        "\n",
        "# In Ordinary Least Squares Regression, \n",
        "\n",
        "# J(w0,w1)= 1/2m x Sum(y-y`)^2"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c8W-Uo_l9_9"
      },
      "source": [
        "# # PseudoCode\n",
        "# 1. Start with random values of w0 and w2\n",
        "# 2. Calculate error term after getting output\n",
        "# 3. repeat till convergence:\n",
        "#     a. Find the change to be made in w0 so that error is min\n",
        "#     b. Find the change to be made in w1 so that error is min\n",
        "#     c. Update the weights \n",
        "#     d. Find predictions\n",
        "\n",
        "# repeat until convergence  {\n",
        "#        tmpi = wi - alpha * dwi          \n",
        "#        wi = tmpi              \n",
        "# }\n",
        "# where alpha is the learning rate."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHdLjovBIdg"
      },
      "source": [
        "X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "Y = np.array([0, 2, 4, 5, 8, 9, 12, 14, 16, 19])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxoFH_04_ygG",
        "outputId": "e3af11eb-2d16-4df8-c5f9-52b9a7d07896"
      },
      "source": [
        "for x,y in zip(X,Y):\n",
        "  print(x,y)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "1 2\n",
            "2 4\n",
            "3 5\n",
            "4 8\n",
            "5 9\n",
            "6 12\n",
            "7 14\n",
            "8 16\n",
            "9 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAYzNkC_4NDZ"
      },
      "source": [
        "class LinearRegression:\n",
        "\n",
        "  X = None\n",
        "  Y = None\n",
        "  b = None\n",
        "  learning_rate = None\n",
        "  iterations = None\n",
        "\n",
        "  def __init__(self, learning_rate=0.01, iterations=500):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.iterations = iterations\n",
        "\n",
        "  def initial_weights(self):\n",
        "     # weight initialization\n",
        "      self.W = np.zeros( self.n )\n",
        "      self.b = 0\n",
        "      \n",
        "\n",
        "  def fit( self, X, Y ) :\n",
        "     \n",
        "      # no_of_training_examples, no_of_features\n",
        "      self.m, self.n = X.shape[0] if len(X.shape)>1 else X.shape[0],1\n",
        "      self.X = X\n",
        "      self.Y = Y\n",
        "      \n",
        "      self.initial_weights()\n",
        "\n",
        "      # gradient descent learning   \n",
        "      for i in range( self.iterations ) :   \n",
        "          print(\"Iteration \",i, \"W:\",self.W,\", b:\",self.b) \n",
        "          self.update_weights()\n",
        "            \n",
        "      return self\n",
        "\n",
        "\n",
        "  def h(self,x) :\n",
        "    return self.W*x+self.b\n",
        "       \n",
        "\n",
        "  def update_weights( self ) :\n",
        "             \n",
        "        error = 0\n",
        "        for (x,y) in zip(X,Y):\n",
        "          y_pred = self.h(x)\n",
        "          y_actual = y\n",
        "          error += (y_pred - y_actual)*(y_pred - y_actual)\n",
        "        self.error = error\n",
        "        dW = -1*(self.learning_rate/self.m)*error*x\n",
        "       \n",
        "        db = -1*(self.learning_rate/self.m)*error\n",
        "          \n",
        "        # update weights\n",
        "      \n",
        "        self.W = self.W - self.learning_rate * dW\n",
        "        self.b = self.b - self.learning_rate * db\n",
        "        print\n",
        "        return self"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uGEeUWp40Ji",
        "outputId": "f280a4a3-2f6c-454b-a144-ad63bb1d2431"
      },
      "source": [
        "l = LinearRegression()\n",
        "model = l.fit(X,Y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration  0 W: [0.] , b: 0\n",
            "Iteration  1 W: [0.10323] , b: [0.01147]\n",
            "Iteration  2 W: [0.19594932] , b: [0.02177215]\n",
            "Iteration  3 W: [0.2797107] , b: [0.03107897]\n",
            "Iteration  4 W: [0.35577224] , b: [0.03953025]\n",
            "Iteration  5 W: [0.42516464] , b: [0.04724052]\n",
            "Iteration  6 W: [0.48874074] , b: [0.05430453]\n",
            "Iteration  7 W: [0.5472126] , b: [0.0608014]\n",
            "Iteration  8 W: [0.60117955] , b: [0.06679773]\n",
            "Iteration  9 W: [0.65114985] , b: [0.07234998]\n",
            "Iteration  10 W: [0.69755743] , b: [0.07750638]\n",
            "Iteration  11 W: [0.7407751] , b: [0.08230834]\n",
            "Iteration  12 W: [0.781125] , b: [0.08679167]\n",
            "Iteration  13 W: [0.818887] , b: [0.09098744]\n",
            "Iteration  14 W: [0.85430542] , b: [0.09492282]\n",
            "Iteration  15 W: [0.88759455] , b: [0.09862162]\n",
            "Iteration  16 W: [0.91894314] , b: [0.10210479]\n",
            "Iteration  17 W: [0.94851815] , b: [0.10539091]\n",
            "Iteration  18 W: [0.97646777] , b: [0.10849642]\n",
            "Iteration  19 W: [1.00292404] , b: [0.111436]\n",
            "Iteration  20 W: [1.02800497] , b: [0.11422277]\n",
            "Iteration  21 W: [1.0518164] , b: [0.11686849]\n",
            "Iteration  22 W: [1.0744535] , b: [0.11938372]\n",
            "Iteration  23 W: [1.09600213] , b: [0.12177801]\n",
            "Iteration  24 W: [1.1165399] , b: [0.12405999]\n",
            "Iteration  25 W: [1.1361372] , b: [0.12623747]\n",
            "Iteration  26 W: [1.15485798] , b: [0.12831755]\n",
            "Iteration  27 W: [1.1727605] , b: [0.13030672]\n",
            "Iteration  28 W: [1.18989795] , b: [0.13221088]\n",
            "Iteration  29 W: [1.20631896] , b: [0.13403544]\n",
            "Iteration  30 W: [1.22206812] , b: [0.13578535]\n",
            "Iteration  31 W: [1.23718638] , b: [0.13746515]\n",
            "Iteration  32 W: [1.25171141] , b: [0.13907905]\n",
            "Iteration  33 W: [1.26567792] , b: [0.14063088]\n",
            "Iteration  34 W: [1.27911796] , b: [0.14212422]\n",
            "Iteration  35 W: [1.29206116] , b: [0.14356235]\n",
            "Iteration  36 W: [1.30453495] , b: [0.14494833]\n",
            "Iteration  37 W: [1.31656477] , b: [0.14628497]\n",
            "Iteration  38 W: [1.32817427] , b: [0.14757492]\n",
            "Iteration  39 W: [1.33938542] , b: [0.1488206]\n",
            "Iteration  40 W: [1.35021867] , b: [0.1500243]\n",
            "Iteration  41 W: [1.36069311] , b: [0.15118812]\n",
            "Iteration  42 W: [1.37082656] , b: [0.15231406]\n",
            "Iteration  43 W: [1.38063566] , b: [0.15340396]\n",
            "Iteration  44 W: [1.39013598] , b: [0.15445955]\n",
            "Iteration  45 W: [1.39934213] , b: [0.15548246]\n",
            "Iteration  46 W: [1.40826778] , b: [0.1564742]\n",
            "Iteration  47 W: [1.41692578] , b: [0.1574362]\n",
            "Iteration  48 W: [1.42532819] , b: [0.1583698]\n",
            "Iteration  49 W: [1.43348638] , b: [0.15927626]\n",
            "Iteration  50 W: [1.44141103] , b: [0.16015678]\n",
            "Iteration  51 W: [1.4491122] , b: [0.16101247]\n",
            "Iteration  52 W: [1.4565994] , b: [0.16184438]\n",
            "Iteration  53 W: [1.46388159] , b: [0.16265351]\n",
            "Iteration  54 W: [1.47096725] , b: [0.16344081]\n",
            "Iteration  55 W: [1.47786438] , b: [0.16420715]\n",
            "Iteration  56 W: [1.48458055] , b: [0.16495339]\n",
            "Iteration  57 W: [1.49112295] , b: [0.16568033]\n",
            "Iteration  58 W: [1.49749837] , b: [0.16638871]\n",
            "Iteration  59 W: [1.50371327] , b: [0.16707925]\n",
            "Iteration  60 W: [1.50977377] , b: [0.16775264]\n",
            "Iteration  61 W: [1.51568566] , b: [0.16840952]\n",
            "Iteration  62 W: [1.52145449] , b: [0.1690505]\n",
            "Iteration  63 W: [1.5270855] , b: [0.16967617]\n",
            "Iteration  64 W: [1.53258369] , b: [0.17028708]\n",
            "Iteration  65 W: [1.53795382] , b: [0.17088376]\n",
            "Iteration  66 W: [1.54320041] , b: [0.17146671]\n",
            "Iteration  67 W: [1.5483278] , b: [0.17203642]\n",
            "Iteration  68 W: [1.5533401] , b: [0.17259334]\n",
            "Iteration  69 W: [1.55824125] , b: [0.17313792]\n",
            "Iteration  70 W: [1.563035] , b: [0.17367056]\n",
            "Iteration  71 W: [1.56772494] , b: [0.17419166]\n",
            "Iteration  72 W: [1.57231449] , b: [0.17470161]\n",
            "Iteration  73 W: [1.57680695] , b: [0.17520077]\n",
            "Iteration  74 W: [1.58120544] , b: [0.17568949]\n",
            "Iteration  75 W: [1.58551297] , b: [0.17616811]\n",
            "Iteration  76 W: [1.58973242] , b: [0.17663694]\n",
            "Iteration  77 W: [1.59386654] , b: [0.17709628]\n",
            "Iteration  78 W: [1.59791798] , b: [0.17754644]\n",
            "Iteration  79 W: [1.60188928] , b: [0.1779877]\n",
            "Iteration  80 W: [1.60578285] , b: [0.17842032]\n",
            "Iteration  81 W: [1.60960105] , b: [0.17884456]\n",
            "Iteration  82 W: [1.6133461] , b: [0.17926068]\n",
            "Iteration  83 W: [1.61702017] , b: [0.17966891]\n",
            "Iteration  84 W: [1.62062532] , b: [0.18006948]\n",
            "Iteration  85 W: [1.62416354] , b: [0.18046262]\n",
            "Iteration  86 W: [1.62763674] , b: [0.18084853]\n",
            "Iteration  87 W: [1.63104678] , b: [0.18122742]\n",
            "Iteration  88 W: [1.63439541] , b: [0.18159949]\n",
            "Iteration  89 W: [1.63768435] , b: [0.18196493]\n",
            "Iteration  90 W: [1.64091524] , b: [0.18232392]\n",
            "Iteration  91 W: [1.64408967] , b: [0.18267663]\n",
            "Iteration  92 W: [1.64720916] , b: [0.18302324]\n",
            "Iteration  93 W: [1.65027518] , b: [0.18336391]\n",
            "Iteration  94 W: [1.65328915] , b: [0.18369879]\n",
            "Iteration  95 W: [1.65625245] , b: [0.18402805]\n",
            "Iteration  96 W: [1.65916639] , b: [0.18435182]\n",
            "Iteration  97 W: [1.66203226] , b: [0.18467025]\n",
            "Iteration  98 W: [1.66485129] , b: [0.18498348]\n",
            "Iteration  99 W: [1.66762466] , b: [0.18529163]\n",
            "Iteration  100 W: [1.67035353] , b: [0.18559484]\n",
            "Iteration  101 W: [1.67303902] , b: [0.18589322]\n",
            "Iteration  102 W: [1.67568219] , b: [0.18618691]\n",
            "Iteration  103 W: [1.67828409] , b: [0.18647601]\n",
            "Iteration  104 W: [1.68084573] , b: [0.18676064]\n",
            "Iteration  105 W: [1.68336807] , b: [0.1870409]\n",
            "Iteration  106 W: [1.68585207] , b: [0.1873169]\n",
            "Iteration  107 W: [1.68829864] , b: [0.18758874]\n",
            "Iteration  108 W: [1.69070866] , b: [0.18785652]\n",
            "Iteration  109 W: [1.69308298] , b: [0.18812033]\n",
            "Iteration  110 W: [1.69542245] , b: [0.18838027]\n",
            "Iteration  111 W: [1.69772786] , b: [0.18863643]\n",
            "Iteration  112 W: [1.69999999] , b: [0.18888889]\n",
            "Iteration  113 W: [1.7022396] , b: [0.18913773]\n",
            "Iteration  114 W: [1.70444743] , b: [0.18938305]\n",
            "Iteration  115 W: [1.70662418] , b: [0.18962491]\n",
            "Iteration  116 W: [1.70877054] , b: [0.18986339]\n",
            "Iteration  117 W: [1.7108872] , b: [0.19009858]\n",
            "Iteration  118 W: [1.71297479] , b: [0.19033053]\n",
            "Iteration  119 W: [1.71503395] , b: [0.19055933]\n",
            "Iteration  120 W: [1.7170653] , b: [0.19078503]\n",
            "Iteration  121 W: [1.71906943] , b: [0.19100771]\n",
            "Iteration  122 W: [1.72104692] , b: [0.19122744]\n",
            "Iteration  123 W: [1.72299833] , b: [0.19144426]\n",
            "Iteration  124 W: [1.72492421] , b: [0.19165825]\n",
            "Iteration  125 W: [1.7268251] , b: [0.19186946]\n",
            "Iteration  126 W: [1.7287015] , b: [0.19207794]\n",
            "Iteration  127 W: [1.73055394] , b: [0.19228377]\n",
            "Iteration  128 W: [1.73238288] , b: [0.19248699]\n",
            "Iteration  129 W: [1.73418882] , b: [0.19268765]\n",
            "Iteration  130 W: [1.73597221] , b: [0.1928858]\n",
            "Iteration  131 W: [1.73773351] , b: [0.1930815]\n",
            "Iteration  132 W: [1.73947315] , b: [0.19327479]\n",
            "Iteration  133 W: [1.74119157] , b: [0.19346573]\n",
            "Iteration  134 W: [1.74288917] , b: [0.19365435]\n",
            "Iteration  135 W: [1.74456638] , b: [0.19384071]\n",
            "Iteration  136 W: [1.74622357] , b: [0.19402484]\n",
            "Iteration  137 W: [1.74786115] , b: [0.19420679]\n",
            "Iteration  138 W: [1.74947947] , b: [0.19438661]\n",
            "Iteration  139 W: [1.75107892] , b: [0.19456432]\n",
            "Iteration  140 W: [1.75265984] , b: [0.19473998]\n",
            "Iteration  141 W: [1.75422259] , b: [0.19491362]\n",
            "Iteration  142 W: [1.7557675] , b: [0.19508528]\n",
            "Iteration  143 W: [1.7572949] , b: [0.19525499]\n",
            "Iteration  144 W: [1.75880513] , b: [0.19542279]\n",
            "Iteration  145 W: [1.76029848] , b: [0.19558872]\n",
            "Iteration  146 W: [1.76177528] , b: [0.19575281]\n",
            "Iteration  147 W: [1.76323582] , b: [0.19591509]\n",
            "Iteration  148 W: [1.76468039] , b: [0.1960756]\n",
            "Iteration  149 W: [1.76610928] , b: [0.19623436]\n",
            "Iteration  150 W: [1.76752277] , b: [0.19639142]\n",
            "Iteration  151 W: [1.76892114] , b: [0.19654679]\n",
            "Iteration  152 W: [1.77030464] , b: [0.19670052]\n",
            "Iteration  153 W: [1.77167354] , b: [0.19685262]\n",
            "Iteration  154 W: [1.77302809] , b: [0.19700312]\n",
            "Iteration  155 W: [1.77436854] , b: [0.19715206]\n",
            "Iteration  156 W: [1.77569513] , b: [0.19729946]\n",
            "Iteration  157 W: [1.77700811] , b: [0.19744535]\n",
            "Iteration  158 W: [1.7783077] , b: [0.19758974]\n",
            "Iteration  159 W: [1.77959413] , b: [0.19773268]\n",
            "Iteration  160 W: [1.78086761] , b: [0.19787418]\n",
            "Iteration  161 W: [1.78212838] , b: [0.19801426]\n",
            "Iteration  162 W: [1.78337664] , b: [0.19815296]\n",
            "Iteration  163 W: [1.78461259] , b: [0.19829029]\n",
            "Iteration  164 W: [1.78583644] , b: [0.19842627]\n",
            "Iteration  165 W: [1.78704839] , b: [0.19856093]\n",
            "Iteration  166 W: [1.78824863] , b: [0.19869429]\n",
            "Iteration  167 W: [1.78943736] , b: [0.19882637]\n",
            "Iteration  168 W: [1.79061475] , b: [0.19895719]\n",
            "Iteration  169 W: [1.791781] , b: [0.19908678]\n",
            "Iteration  170 W: [1.79293627] , b: [0.19921514]\n",
            "Iteration  171 W: [1.79408074] , b: [0.1993423]\n",
            "Iteration  172 W: [1.79521459] , b: [0.19946829]\n",
            "Iteration  173 W: [1.79633798] , b: [0.19959311]\n",
            "Iteration  174 W: [1.79745108] , b: [0.19971679]\n",
            "Iteration  175 W: [1.79855404] , b: [0.19983934]\n",
            "Iteration  176 W: [1.79964702] , b: [0.19996078]\n",
            "Iteration  177 W: [1.80073018] , b: [0.20008113]\n",
            "Iteration  178 W: [1.80180366] , b: [0.20020041]\n",
            "Iteration  179 W: [1.80286763] , b: [0.20031863]\n",
            "Iteration  180 W: [1.80392221] , b: [0.2004358]\n",
            "Iteration  181 W: [1.80496755] , b: [0.20055195]\n",
            "Iteration  182 W: [1.8060038] , b: [0.20066709]\n",
            "Iteration  183 W: [1.80703108] , b: [0.20078123]\n",
            "Iteration  184 W: [1.80804954] , b: [0.20089439]\n",
            "Iteration  185 W: [1.80905929] , b: [0.20100659]\n",
            "Iteration  186 W: [1.81006048] , b: [0.20111783]\n",
            "Iteration  187 W: [1.81105323] , b: [0.20122814]\n",
            "Iteration  188 W: [1.81203766] , b: [0.20133752]\n",
            "Iteration  189 W: [1.81301389] , b: [0.20144599]\n",
            "Iteration  190 W: [1.81398205] , b: [0.20155356]\n",
            "Iteration  191 W: [1.81494224] , b: [0.20166025]\n",
            "Iteration  192 W: [1.81589459] , b: [0.20176607]\n",
            "Iteration  193 W: [1.8168392] , b: [0.20187102]\n",
            "Iteration  194 W: [1.81777619] , b: [0.20197513]\n",
            "Iteration  195 W: [1.81870566] , b: [0.20207841]\n",
            "Iteration  196 W: [1.81962773] , b: [0.20218086]\n",
            "Iteration  197 W: [1.82054249] , b: [0.2022825]\n",
            "Iteration  198 W: [1.82145005] , b: [0.20238334]\n",
            "Iteration  199 W: [1.82235051] , b: [0.20248339]\n",
            "Iteration  200 W: [1.82324396] , b: [0.20258266]\n",
            "Iteration  201 W: [1.82413051] , b: [0.20268117]\n",
            "Iteration  202 W: [1.82501025] , b: [0.20277892]\n",
            "Iteration  203 W: [1.82588327] , b: [0.20287592]\n",
            "Iteration  204 W: [1.82674967] , b: [0.20297219]\n",
            "Iteration  205 W: [1.82760953] , b: [0.20306773]\n",
            "Iteration  206 W: [1.82846295] , b: [0.20316255]\n",
            "Iteration  207 W: [1.82931001] , b: [0.20325667]\n",
            "Iteration  208 W: [1.8301508] , b: [0.20335009]\n",
            "Iteration  209 W: [1.83098539] , b: [0.20344282]\n",
            "Iteration  210 W: [1.83181389] , b: [0.20353488]\n",
            "Iteration  211 W: [1.83263635] , b: [0.20362626]\n",
            "Iteration  212 W: [1.83345288] , b: [0.20371699]\n",
            "Iteration  213 W: [1.83426353] , b: [0.20380706]\n",
            "Iteration  214 W: [1.8350684] , b: [0.20389649]\n",
            "Iteration  215 W: [1.83586755] , b: [0.20398528]\n",
            "Iteration  216 W: [1.83666107] , b: [0.20407345]\n",
            "Iteration  217 W: [1.83744901] , b: [0.204161]\n",
            "Iteration  218 W: [1.83823147] , b: [0.20424794]\n",
            "Iteration  219 W: [1.8390085] , b: [0.20433428]\n",
            "Iteration  220 W: [1.83978019] , b: [0.20442002]\n",
            "Iteration  221 W: [1.84054658] , b: [0.20450518]\n",
            "Iteration  222 W: [1.84130776] , b: [0.20458975]\n",
            "Iteration  223 W: [1.84206379] , b: [0.20467375]\n",
            "Iteration  224 W: [1.84281474] , b: [0.20475719]\n",
            "Iteration  225 W: [1.84356067] , b: [0.20484007]\n",
            "Iteration  226 W: [1.84430163] , b: [0.2049224]\n",
            "Iteration  227 W: [1.84503771] , b: [0.20500419]\n",
            "Iteration  228 W: [1.84576895] , b: [0.20508544]\n",
            "Iteration  229 W: [1.84649541] , b: [0.20516616]\n",
            "Iteration  230 W: [1.84721716] , b: [0.20524635]\n",
            "Iteration  231 W: [1.84793426] , b: [0.20532603]\n",
            "Iteration  232 W: [1.84864676] , b: [0.2054052]\n",
            "Iteration  233 W: [1.84935471] , b: [0.20548386]\n",
            "Iteration  234 W: [1.85005818] , b: [0.20556202]\n",
            "Iteration  235 W: [1.85075722] , b: [0.20563969]\n",
            "Iteration  236 W: [1.85145188] , b: [0.20571688]\n",
            "Iteration  237 W: [1.85214221] , b: [0.20579358]\n",
            "Iteration  238 W: [1.85282827] , b: [0.20586981]\n",
            "Iteration  239 W: [1.85351012] , b: [0.20594557]\n",
            "Iteration  240 W: [1.85418779] , b: [0.20602087]\n",
            "Iteration  241 W: [1.85486134] , b: [0.2060957]\n",
            "Iteration  242 W: [1.85553083] , b: [0.20617009]\n",
            "Iteration  243 W: [1.85619629] , b: [0.20624403]\n",
            "Iteration  244 W: [1.85685777] , b: [0.20631753]\n",
            "Iteration  245 W: [1.85751533] , b: [0.20639059]\n",
            "Iteration  246 W: [1.85816901] , b: [0.20646322]\n",
            "Iteration  247 W: [1.85881885] , b: [0.20653543]\n",
            "Iteration  248 W: [1.8594649] , b: [0.20660721]\n",
            "Iteration  249 W: [1.86010721] , b: [0.20667858]\n",
            "Iteration  250 W: [1.86074581] , b: [0.20674953]\n",
            "Iteration  251 W: [1.86138076] , b: [0.20682008]\n",
            "Iteration  252 W: [1.86201208] , b: [0.20689023]\n",
            "Iteration  253 W: [1.86263984] , b: [0.20695998]\n",
            "Iteration  254 W: [1.86326405] , b: [0.20702934]\n",
            "Iteration  255 W: [1.86388478] , b: [0.20709831]\n",
            "Iteration  256 W: [1.86450205] , b: [0.20716689]\n",
            "Iteration  257 W: [1.86511591] , b: [0.2072351]\n",
            "Iteration  258 W: [1.8657264] , b: [0.20730293]\n",
            "Iteration  259 W: [1.86633355] , b: [0.20737039]\n",
            "Iteration  260 W: [1.8669374] , b: [0.20743749]\n",
            "Iteration  261 W: [1.86753799] , b: [0.20750422]\n",
            "Iteration  262 W: [1.86813535] , b: [0.20757059]\n",
            "Iteration  263 W: [1.86872953] , b: [0.20763661]\n",
            "Iteration  264 W: [1.86932056] , b: [0.20770228]\n",
            "Iteration  265 W: [1.86990847] , b: [0.20776761]\n",
            "Iteration  266 W: [1.87049329] , b: [0.20783259]\n",
            "Iteration  267 W: [1.87107507] , b: [0.20789723]\n",
            "Iteration  268 W: [1.87165384] , b: [0.20796154]\n",
            "Iteration  269 W: [1.87222963] , b: [0.20802551]\n",
            "Iteration  270 W: [1.87280247] , b: [0.20808916]\n",
            "Iteration  271 W: [1.87337239] , b: [0.20815249]\n",
            "Iteration  272 W: [1.87393944] , b: [0.20821549]\n",
            "Iteration  273 W: [1.87450363] , b: [0.20827818]\n",
            "Iteration  274 W: [1.875065] , b: [0.20834056]\n",
            "Iteration  275 W: [1.87562358] , b: [0.20840262]\n",
            "Iteration  276 W: [1.87617941] , b: [0.20846438]\n",
            "Iteration  277 W: [1.87673251] , b: [0.20852583]\n",
            "Iteration  278 W: [1.87728291] , b: [0.20858699]\n",
            "Iteration  279 W: [1.87783064] , b: [0.20864785]\n",
            "Iteration  280 W: [1.87837573] , b: [0.20870841]\n",
            "Iteration  281 W: [1.87891821] , b: [0.20876869]\n",
            "Iteration  282 W: [1.87945811] , b: [0.20882868]\n",
            "Iteration  283 W: [1.87999545] , b: [0.20888838]\n",
            "Iteration  284 W: [1.88053026] , b: [0.20894781]\n",
            "Iteration  285 W: [1.88106257] , b: [0.20900695]\n",
            "Iteration  286 W: [1.88159241] , b: [0.20906582]\n",
            "Iteration  287 W: [1.8821198] , b: [0.20912442]\n",
            "Iteration  288 W: [1.88264477] , b: [0.20918275]\n",
            "Iteration  289 W: [1.88316734] , b: [0.20924082]\n",
            "Iteration  290 W: [1.88368754] , b: [0.20929862]\n",
            "Iteration  291 W: [1.8842054] , b: [0.20935616]\n",
            "Iteration  292 W: [1.88472093] , b: [0.20941344]\n",
            "Iteration  293 W: [1.88523417] , b: [0.20947046]\n",
            "Iteration  294 W: [1.88574514] , b: [0.20952724]\n",
            "Iteration  295 W: [1.88625387] , b: [0.20958376]\n",
            "Iteration  296 W: [1.88676036] , b: [0.20964004]\n",
            "Iteration  297 W: [1.88726466] , b: [0.20969607]\n",
            "Iteration  298 W: [1.88776678] , b: [0.20975186]\n",
            "Iteration  299 W: [1.88826675] , b: [0.20980742]\n",
            "Iteration  300 W: [1.88876458] , b: [0.20986273]\n",
            "Iteration  301 W: [1.8892603] , b: [0.20991781]\n",
            "Iteration  302 W: [1.88975394] , b: [0.20997266]\n",
            "Iteration  303 W: [1.89024551] , b: [0.21002728]\n",
            "Iteration  304 W: [1.89073503] , b: [0.21008167]\n",
            "Iteration  305 W: [1.89122254] , b: [0.21013584]\n",
            "Iteration  306 W: [1.89170804] , b: [0.21018978]\n",
            "Iteration  307 W: [1.89219156] , b: [0.21024351]\n",
            "Iteration  308 W: [1.89267311] , b: [0.21029701]\n",
            "Iteration  309 W: [1.89315273] , b: [0.2103503]\n",
            "Iteration  310 W: [1.89363043] , b: [0.21040338]\n",
            "Iteration  311 W: [1.89410622] , b: [0.21045625]\n",
            "Iteration  312 W: [1.89458014] , b: [0.2105089]\n",
            "Iteration  313 W: [1.89505219] , b: [0.21056135]\n",
            "Iteration  314 W: [1.8955224] , b: [0.2106136]\n",
            "Iteration  315 W: [1.89599079] , b: [0.21066564]\n",
            "Iteration  316 W: [1.89645737] , b: [0.21071749]\n",
            "Iteration  317 W: [1.89692217] , b: [0.21076913]\n",
            "Iteration  318 W: [1.8973852] , b: [0.21082058]\n",
            "Iteration  319 W: [1.89784648] , b: [0.21087183]\n",
            "Iteration  320 W: [1.89830602] , b: [0.21092289]\n",
            "Iteration  321 W: [1.89876386] , b: [0.21097376]\n",
            "Iteration  322 W: [1.89921999] , b: [0.21102444]\n",
            "Iteration  323 W: [1.89967445] , b: [0.21107494]\n",
            "Iteration  324 W: [1.90012724] , b: [0.21112525]\n",
            "Iteration  325 W: [1.90057839] , b: [0.21117538]\n",
            "Iteration  326 W: [1.90102792] , b: [0.21122532]\n",
            "Iteration  327 W: [1.90147583] , b: [0.21127509]\n",
            "Iteration  328 W: [1.90192214] , b: [0.21132468]\n",
            "Iteration  329 W: [1.90236688] , b: [0.2113741]\n",
            "Iteration  330 W: [1.90281005] , b: [0.21142334]\n",
            "Iteration  331 W: [1.90325168] , b: [0.21147241]\n",
            "Iteration  332 W: [1.90369177] , b: [0.21152131]\n",
            "Iteration  333 W: [1.90413035] , b: [0.21157004]\n",
            "Iteration  334 W: [1.90456743] , b: [0.2116186]\n",
            "Iteration  335 W: [1.90500303] , b: [0.211667]\n",
            "Iteration  336 W: [1.90543716] , b: [0.21171524]\n",
            "Iteration  337 W: [1.90586983] , b: [0.21176331]\n",
            "Iteration  338 W: [1.90630106] , b: [0.21181123]\n",
            "Iteration  339 W: [1.90673087] , b: [0.21185899]\n",
            "Iteration  340 W: [1.90715926] , b: [0.21190658]\n",
            "Iteration  341 W: [1.90758626] , b: [0.21195403]\n",
            "Iteration  342 W: [1.90801188] , b: [0.21200132]\n",
            "Iteration  343 W: [1.90843613] , b: [0.21204846]\n",
            "Iteration  344 W: [1.90885903] , b: [0.21209545]\n",
            "Iteration  345 W: [1.90928059] , b: [0.21214229]\n",
            "Iteration  346 W: [1.90970082] , b: [0.21218898]\n",
            "Iteration  347 W: [1.91011973] , b: [0.21223553]\n",
            "Iteration  348 W: [1.91053735] , b: [0.21228193]\n",
            "Iteration  349 W: [1.91095369] , b: [0.21232819]\n",
            "Iteration  350 W: [1.91136875] , b: [0.21237431]\n",
            "Iteration  351 W: [1.91178255] , b: [0.21242028]\n",
            "Iteration  352 W: [1.9121951] , b: [0.21246612]\n",
            "Iteration  353 W: [1.91260642] , b: [0.21251182]\n",
            "Iteration  354 W: [1.91301652] , b: [0.21255739]\n",
            "Iteration  355 W: [1.91342541] , b: [0.21260282]\n",
            "Iteration  356 W: [1.91383311] , b: [0.21264812]\n",
            "Iteration  357 W: [1.91423962] , b: [0.21269329]\n",
            "Iteration  358 W: [1.91464495] , b: [0.21273833]\n",
            "Iteration  359 W: [1.91504913] , b: [0.21278324]\n",
            "Iteration  360 W: [1.91545217] , b: [0.21282802]\n",
            "Iteration  361 W: [1.91585406] , b: [0.21287267]\n",
            "Iteration  362 W: [1.91625483] , b: [0.2129172]\n",
            "Iteration  363 W: [1.91665449] , b: [0.21296161]\n",
            "Iteration  364 W: [1.91705305] , b: [0.21300589]\n",
            "Iteration  365 W: [1.91745052] , b: [0.21305006]\n",
            "Iteration  366 W: [1.91784692] , b: [0.2130941]\n",
            "Iteration  367 W: [1.91824224] , b: [0.21313803]\n",
            "Iteration  368 W: [1.91863651] , b: [0.21318183]\n",
            "Iteration  369 W: [1.91902974] , b: [0.21322553]\n",
            "Iteration  370 W: [1.91942194] , b: [0.2132691]\n",
            "Iteration  371 W: [1.91981311] , b: [0.21331257]\n",
            "Iteration  372 W: [1.92020327] , b: [0.21335592]\n",
            "Iteration  373 W: [1.92059243] , b: [0.21339916]\n",
            "Iteration  374 W: [1.9209806] , b: [0.21344229]\n",
            "Iteration  375 W: [1.92136779] , b: [0.21348531]\n",
            "Iteration  376 W: [1.92175401] , b: [0.21352822]\n",
            "Iteration  377 W: [1.92213927] , b: [0.21357103]\n",
            "Iteration  378 W: [1.92252358] , b: [0.21361373]\n",
            "Iteration  379 W: [1.92290696] , b: [0.21365633]\n",
            "Iteration  380 W: [1.92328941] , b: [0.21369882]\n",
            "Iteration  381 W: [1.92367094] , b: [0.21374122]\n",
            "Iteration  382 W: [1.92405156] , b: [0.21378351]\n",
            "Iteration  383 W: [1.92443128] , b: [0.2138257]\n",
            "Iteration  384 W: [1.92481011] , b: [0.21386779]\n",
            "Iteration  385 W: [1.92518807] , b: [0.21390979]\n",
            "Iteration  386 W: [1.92556515] , b: [0.21395168]\n",
            "Iteration  387 W: [1.92594138] , b: [0.21399349]\n",
            "Iteration  388 W: [1.92631676] , b: [0.2140352]\n",
            "Iteration  389 W: [1.92669129] , b: [0.21407681]\n",
            "Iteration  390 W: [1.92706499] , b: [0.21411833]\n",
            "Iteration  391 W: [1.92743788] , b: [0.21415976]\n",
            "Iteration  392 W: [1.92780994] , b: [0.2142011]\n",
            "Iteration  393 W: [1.92818121] , b: [0.21424236]\n",
            "Iteration  394 W: [1.92855168] , b: [0.21428352]\n",
            "Iteration  395 W: [1.92892136] , b: [0.2143246]\n",
            "Iteration  396 W: [1.92929027] , b: [0.21436559]\n",
            "Iteration  397 W: [1.92965841] , b: [0.21440649]\n",
            "Iteration  398 W: [1.93002579] , b: [0.21444731]\n",
            "Iteration  399 W: [1.93039242] , b: [0.21448805]\n",
            "Iteration  400 W: [1.93075831] , b: [0.2145287]\n",
            "Iteration  401 W: [1.93112347] , b: [0.21456927]\n",
            "Iteration  402 W: [1.9314879] , b: [0.21460977]\n",
            "Iteration  403 W: [1.93185161] , b: [0.21465018]\n",
            "Iteration  404 W: [1.93221462] , b: [0.21469051]\n",
            "Iteration  405 W: [1.93257693] , b: [0.21473077]\n",
            "Iteration  406 W: [1.93293855] , b: [0.21477095]\n",
            "Iteration  407 W: [1.93329948] , b: [0.21481105]\n",
            "Iteration  408 W: [1.93365974] , b: [0.21485108]\n",
            "Iteration  409 W: [1.93401934] , b: [0.21489104]\n",
            "Iteration  410 W: [1.93437827] , b: [0.21493092]\n",
            "Iteration  411 W: [1.93473656] , b: [0.21497073]\n",
            "Iteration  412 W: [1.9350942] , b: [0.21501047]\n",
            "Iteration  413 W: [1.93545121] , b: [0.21505013]\n",
            "Iteration  414 W: [1.9358076] , b: [0.21508973]\n",
            "Iteration  415 W: [1.93616336] , b: [0.21512926]\n",
            "Iteration  416 W: [1.93651852] , b: [0.21516872]\n",
            "Iteration  417 W: [1.93687307] , b: [0.21520812]\n",
            "Iteration  418 W: [1.93722702] , b: [0.21524745]\n",
            "Iteration  419 W: [1.93758039] , b: [0.21528671]\n",
            "Iteration  420 W: [1.93793318] , b: [0.21532591]\n",
            "Iteration  421 W: [1.9382854] , b: [0.21536504]\n",
            "Iteration  422 W: [1.93863705] , b: [0.21540412]\n",
            "Iteration  423 W: [1.93898815] , b: [0.21544313]\n",
            "Iteration  424 W: [1.9393387] , b: [0.21548208]\n",
            "Iteration  425 W: [1.9396887] , b: [0.21552097]\n",
            "Iteration  426 W: [1.94003817] , b: [0.2155598]\n",
            "Iteration  427 W: [1.94038711] , b: [0.21559857]\n",
            "Iteration  428 W: [1.94073553] , b: [0.21563728]\n",
            "Iteration  429 W: [1.94108343] , b: [0.21567594]\n",
            "Iteration  430 W: [1.94143083] , b: [0.21571454]\n",
            "Iteration  431 W: [1.94177774] , b: [0.21575308]\n",
            "Iteration  432 W: [1.94212415] , b: [0.21579157]\n",
            "Iteration  433 W: [1.94247007] , b: [0.21583001]\n",
            "Iteration  434 W: [1.94281552] , b: [0.21586839]\n",
            "Iteration  435 W: [1.9431605] , b: [0.21590672]\n",
            "Iteration  436 W: [1.94350501] , b: [0.215945]\n",
            "Iteration  437 W: [1.94384907] , b: [0.21598323]\n",
            "Iteration  438 W: [1.94419267] , b: [0.21602141]\n",
            "Iteration  439 W: [1.94453584] , b: [0.21605954]\n",
            "Iteration  440 W: [1.94487856] , b: [0.21609762]\n",
            "Iteration  441 W: [1.94522086] , b: [0.21613565]\n",
            "Iteration  442 W: [1.94556274] , b: [0.21617364]\n",
            "Iteration  443 W: [1.9459042] , b: [0.21621158]\n",
            "Iteration  444 W: [1.94624525] , b: [0.21624947]\n",
            "Iteration  445 W: [1.94658589] , b: [0.21628732]\n",
            "Iteration  446 W: [1.94692615] , b: [0.21632513]\n",
            "Iteration  447 W: [1.94726601] , b: [0.21636289]\n",
            "Iteration  448 W: [1.94760549] , b: [0.21640061]\n",
            "Iteration  449 W: [1.94794459] , b: [0.21643829]\n",
            "Iteration  450 W: [1.94828333] , b: [0.21647593]\n",
            "Iteration  451 W: [1.9486217] , b: [0.21651352]\n",
            "Iteration  452 W: [1.94895971] , b: [0.21655108]\n",
            "Iteration  453 W: [1.94929738] , b: [0.2165886]\n",
            "Iteration  454 W: [1.9496347] , b: [0.21662608]\n",
            "Iteration  455 W: [1.94997168] , b: [0.21666352]\n",
            "Iteration  456 W: [1.95030833] , b: [0.21670093]\n",
            "Iteration  457 W: [1.95064466] , b: [0.2167383]\n",
            "Iteration  458 W: [1.95098067] , b: [0.21677563]\n",
            "Iteration  459 W: [1.95131637] , b: [0.21681293]\n",
            "Iteration  460 W: [1.95165176] , b: [0.2168502]\n",
            "Iteration  461 W: [1.95198685] , b: [0.21688743]\n",
            "Iteration  462 W: [1.95232165] , b: [0.21692463]\n",
            "Iteration  463 W: [1.95265617] , b: [0.2169618]\n",
            "Iteration  464 W: [1.9529904] , b: [0.21699893]\n",
            "Iteration  465 W: [1.95332435] , b: [0.21703604]\n",
            "Iteration  466 W: [1.95365804] , b: [0.21707312]\n",
            "Iteration  467 W: [1.95399147] , b: [0.21711016]\n",
            "Iteration  468 W: [1.95432464] , b: [0.21714718]\n",
            "Iteration  469 W: [1.95465756] , b: [0.21718417]\n",
            "Iteration  470 W: [1.95499023] , b: [0.21722114]\n",
            "Iteration  471 W: [1.95532267] , b: [0.21725807]\n",
            "Iteration  472 W: [1.95565488] , b: [0.21729499]\n",
            "Iteration  473 W: [1.95598686] , b: [0.21733187]\n",
            "Iteration  474 W: [1.95631862] , b: [0.21736874]\n",
            "Iteration  475 W: [1.95665016] , b: [0.21740557]\n",
            "Iteration  476 W: [1.9569815] , b: [0.21744239]\n",
            "Iteration  477 W: [1.95731264] , b: [0.21747918]\n",
            "Iteration  478 W: [1.95764358] , b: [0.21751595]\n",
            "Iteration  479 W: [1.95797433] , b: [0.2175527]\n",
            "Iteration  480 W: [1.95830489] , b: [0.21758943]\n",
            "Iteration  481 W: [1.95863528] , b: [0.21762614]\n",
            "Iteration  482 W: [1.95896549] , b: [0.21766283]\n",
            "Iteration  483 W: [1.95929554] , b: [0.2176995]\n",
            "Iteration  484 W: [1.95962543] , b: [0.21773616]\n",
            "Iteration  485 W: [1.95995516] , b: [0.2177728]\n",
            "Iteration  486 W: [1.96028475] , b: [0.21780942]\n",
            "Iteration  487 W: [1.96061419] , b: [0.21784602]\n",
            "Iteration  488 W: [1.96094349] , b: [0.21788261]\n",
            "Iteration  489 W: [1.96127267] , b: [0.21791919]\n",
            "Iteration  490 W: [1.96160171] , b: [0.21795575]\n",
            "Iteration  491 W: [1.96193064] , b: [0.21799229]\n",
            "Iteration  492 W: [1.96225945] , b: [0.21802883]\n",
            "Iteration  493 W: [1.96258816] , b: [0.21806535]\n",
            "Iteration  494 W: [1.96291676] , b: [0.21810186]\n",
            "Iteration  495 W: [1.96324527] , b: [0.21813836]\n",
            "Iteration  496 W: [1.96357368] , b: [0.21817485]\n",
            "Iteration  497 W: [1.96390201] , b: [0.21821133]\n",
            "Iteration  498 W: [1.96423026] , b: [0.21824781]\n",
            "Iteration  499 W: [1.96455844] , b: [0.21828427]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK71jLvAA9Gz"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naYlmfHJA_y7"
      },
      "source": [
        ""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgsz9dK0B_eX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}